{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e84a27",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcd2e3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data analysis and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure visualization settings\n",
    "sns.set_context(\"notebook\", font_scale=1.5)\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:/Users/pc/Desktop/politecnico/b-FINTECH/business cases/Fintech_BC/BC4/data/Dataset4_EWS.xlsx'\n",
    "#file_path = './data/Dataset4_EWS.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b12a68f",
   "metadata": {},
   "source": [
    "## Real-World dataset\n",
    "\n",
    "From Bloomberg, consisting of weekly observations of:\n",
    "\n",
    "- Market and macroeconomic indicators (e.g., indices, rates).\n",
    "- A response variable `Y` indicating **anomalous periods** (e.g., market stress events)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffa70fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data columns: ['Data', 'BDIY', 'CRY', 'Cl1', 'DXY', 'ECSURPUS', 'EMUSTRUU', 'EONIA', 'GBP', 'GT10', 'GTDEM10Y', 'GTDEM2Y', 'GTDEM30Y', 'GTGBP20Y', 'GTGBP2Y', 'GTGBP30Y', 'GTITL10YR', 'GTITL2YR', 'GTITL30YR', 'GTJPY10YR', 'GTJPY2YR', 'GTJPY30YR', 'JPY', 'LF94TRUU', 'LF98TRUU', 'LG30TRUU', 'LMBITR', 'LP01TREU', 'LUACTRUU', 'LUMSTRUU', 'MXBR', 'MXCN', 'MXEU', 'MXIN', 'MXJP', 'MXRU', 'MXUS', 'US0001M', 'USGG2YR', 'USGG30YR', 'USGG3M', 'VIX', 'XAUBGNL', 'Y']\n",
      "Data shape: (1111, 42)\n",
      "Total number of records: 1111\n",
      "Time period: from 01/11/2000 to 04/20/2021\n",
      "Frequency: W-TUE\n",
      "Number of variables: 42\n",
      "Number of anomalies: 237 (21.33%)\n",
      "\n",
      "Metadata and statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Description</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std.Dev</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Missing values</th>\n",
       "      <th>Missing (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BDIY</td>\n",
       "      <td>Baltic Dry Index</td>\n",
       "      <td>2259.860486</td>\n",
       "      <td>2017.811888</td>\n",
       "      <td>291.00000</td>\n",
       "      <td>11793.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CRY</td>\n",
       "      <td>TR/CC CRB ER Index</td>\n",
       "      <td>245.247649</td>\n",
       "      <td>68.278081</td>\n",
       "      <td>106.29290</td>\n",
       "      <td>467.57000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cl1</td>\n",
       "      <td>Generic 1st 'CL' Future</td>\n",
       "      <td>60.708101</td>\n",
       "      <td>25.900813</td>\n",
       "      <td>10.01000</td>\n",
       "      <td>140.97000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DXY</td>\n",
       "      <td>DOLLAR INDEX SPOT</td>\n",
       "      <td>90.934982</td>\n",
       "      <td>11.379095</td>\n",
       "      <td>71.32900</td>\n",
       "      <td>119.82000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ECSURPUS</td>\n",
       "      <td>Bloomberg ECO US Surprise Inde</td>\n",
       "      <td>0.036153</td>\n",
       "      <td>0.349453</td>\n",
       "      <td>-0.97400</td>\n",
       "      <td>0.99100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EMUSTRUU</td>\n",
       "      <td>EM USD Aggregate</td>\n",
       "      <td>704.379495</td>\n",
       "      <td>309.951768</td>\n",
       "      <td>230.52670</td>\n",
       "      <td>1286.35300</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EONIA</td>\n",
       "      <td>EMMI EURO OverNight Index Aver</td>\n",
       "      <td>1.363676</td>\n",
       "      <td>1.721894</td>\n",
       "      <td>-0.49800</td>\n",
       "      <td>5.73000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GBP</td>\n",
       "      <td>British Pound Spot</td>\n",
       "      <td>1.569618</td>\n",
       "      <td>0.212340</td>\n",
       "      <td>1.17230</td>\n",
       "      <td>2.08520</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GT10</td>\n",
       "      <td>US TREASURY N/B</td>\n",
       "      <td>3.266748</td>\n",
       "      <td>1.332464</td>\n",
       "      <td>0.50800</td>\n",
       "      <td>6.74800</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTDEM10Y</td>\n",
       "      <td>BUNDESREPUB. DEUTSCHLAND</td>\n",
       "      <td>2.448365</td>\n",
       "      <td>1.851558</td>\n",
       "      <td>-0.79400</td>\n",
       "      <td>5.64400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GTDEM2Y</td>\n",
       "      <td>BUNDESSCHATZANWEISUNGEN</td>\n",
       "      <td>1.431110</td>\n",
       "      <td>1.876061</td>\n",
       "      <td>-0.96800</td>\n",
       "      <td>5.26400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GTDEM30Y</td>\n",
       "      <td>BUNDESREPUB. DEUTSCHLAND</td>\n",
       "      <td>3.039282</td>\n",
       "      <td>1.779526</td>\n",
       "      <td>-0.47100</td>\n",
       "      <td>6.25400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GTGBP20Y</td>\n",
       "      <td>UK TSY 1 1/4% 2041</td>\n",
       "      <td>3.445731</td>\n",
       "      <td>1.366188</td>\n",
       "      <td>0.48920</td>\n",
       "      <td>5.24180</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GTGBP2Y</td>\n",
       "      <td>UK TSY 0 1/8% 2023</td>\n",
       "      <td>2.299739</td>\n",
       "      <td>2.128539</td>\n",
       "      <td>-0.16330</td>\n",
       "      <td>6.61250</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GTGBP30Y</td>\n",
       "      <td>UK TSY 0 5/8% 2050</td>\n",
       "      <td>3.450121</td>\n",
       "      <td>1.263211</td>\n",
       "      <td>0.54740</td>\n",
       "      <td>5.07480</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GTITL10YR</td>\n",
       "      <td>BUONI POLIENNALI DEL TES</td>\n",
       "      <td>3.680791</td>\n",
       "      <td>1.465289</td>\n",
       "      <td>0.51200</td>\n",
       "      <td>7.20900</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GTITL2YR</td>\n",
       "      <td>BUONI POLIENNALI DEL TES</td>\n",
       "      <td>2.104911</td>\n",
       "      <td>1.700726</td>\n",
       "      <td>-0.45800</td>\n",
       "      <td>7.01500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GTITL30YR</td>\n",
       "      <td>BUONI POLIENNALI DEL TES</td>\n",
       "      <td>4.426725</td>\n",
       "      <td>1.274729</td>\n",
       "      <td>1.38600</td>\n",
       "      <td>7.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GTJPY10YR</td>\n",
       "      <td>JAPAN (10 YEAR ISSUE)</td>\n",
       "      <td>0.904126</td>\n",
       "      <td>0.643985</td>\n",
       "      <td>-0.29100</td>\n",
       "      <td>1.96800</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GTJPY2YR</td>\n",
       "      <td>JAPAN (2 YEAR ISSUE)</td>\n",
       "      <td>0.150180</td>\n",
       "      <td>0.297519</td>\n",
       "      <td>-0.35100</td>\n",
       "      <td>1.08000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GTJPY30YR</td>\n",
       "      <td>JAPAN (30 YEAR ISSUE)</td>\n",
       "      <td>1.724494</td>\n",
       "      <td>0.720026</td>\n",
       "      <td>0.05600</td>\n",
       "      <td>3.12800</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>JPY</td>\n",
       "      <td>Japanese Yen Spot</td>\n",
       "      <td>106.605734</td>\n",
       "      <td>12.840754</td>\n",
       "      <td>75.94000</td>\n",
       "      <td>134.63000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LF94TRUU</td>\n",
       "      <td>Global Inflation-Linked</td>\n",
       "      <td>259.052663</td>\n",
       "      <td>75.934443</td>\n",
       "      <td>121.33100</td>\n",
       "      <td>398.70650</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LF98TRUU</td>\n",
       "      <td>US Corporate High Yield</td>\n",
       "      <td>1231.258119</td>\n",
       "      <td>553.121000</td>\n",
       "      <td>491.08000</td>\n",
       "      <td>2378.53000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LG30TRUU</td>\n",
       "      <td>Global High Yield</td>\n",
       "      <td>804.720625</td>\n",
       "      <td>370.251996</td>\n",
       "      <td>294.36740</td>\n",
       "      <td>1525.79000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LMBITR</td>\n",
       "      <td>Municipal Bond Index</td>\n",
       "      <td>883.615439</td>\n",
       "      <td>241.507125</td>\n",
       "      <td>472.72330</td>\n",
       "      <td>1350.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LP01TREU</td>\n",
       "      <td>Pan-European High Yield</td>\n",
       "      <td>232.109928</td>\n",
       "      <td>109.917622</td>\n",
       "      <td>80.79680</td>\n",
       "      <td>431.55280</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LUACTRUU</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>2077.306949</td>\n",
       "      <td>690.731794</td>\n",
       "      <td>986.94000</td>\n",
       "      <td>3550.43000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LUMSTRUU</td>\n",
       "      <td>U.S. MBS</td>\n",
       "      <td>1637.293510</td>\n",
       "      <td>417.229338</td>\n",
       "      <td>869.33000</td>\n",
       "      <td>2325.86000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MXBR</td>\n",
       "      <td>MSCI BRAZIL</td>\n",
       "      <td>1903.216436</td>\n",
       "      <td>986.468254</td>\n",
       "      <td>280.50000</td>\n",
       "      <td>4721.36000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MXCN</td>\n",
       "      <td>MSCI CHINA</td>\n",
       "      <td>53.933159</td>\n",
       "      <td>24.738356</td>\n",
       "      <td>13.46000</td>\n",
       "      <td>129.20000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>MXEU</td>\n",
       "      <td>MSCI EUROPE</td>\n",
       "      <td>107.877138</td>\n",
       "      <td>20.795973</td>\n",
       "      <td>56.30000</td>\n",
       "      <td>146.39000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>MXIN</td>\n",
       "      <td>MSCI INDIA</td>\n",
       "      <td>693.156616</td>\n",
       "      <td>405.527014</td>\n",
       "      <td>112.60000</td>\n",
       "      <td>1730.51000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MXJP</td>\n",
       "      <td>MSCI JAPAN</td>\n",
       "      <td>784.846292</td>\n",
       "      <td>200.076443</td>\n",
       "      <td>431.71000</td>\n",
       "      <td>1210.58000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>MXRU</td>\n",
       "      <td>MSCI RUSSIA</td>\n",
       "      <td>648.681377</td>\n",
       "      <td>299.096020</td>\n",
       "      <td>151.25000</td>\n",
       "      <td>1617.64000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MXUS</td>\n",
       "      <td>MSCI USA</td>\n",
       "      <td>1606.997102</td>\n",
       "      <td>698.481956</td>\n",
       "      <td>663.69000</td>\n",
       "      <td>4043.69000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>US0001M</td>\n",
       "      <td>ICE LIBOR USD 1 Month</td>\n",
       "      <td>1.836073</td>\n",
       "      <td>1.909032</td>\n",
       "      <td>0.10575</td>\n",
       "      <td>6.77625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>USGG2YR</td>\n",
       "      <td>US Generic Govt 2 Yr</td>\n",
       "      <td>1.990358</td>\n",
       "      <td>1.710307</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>6.87200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>USGG30YR</td>\n",
       "      <td>US Generic Govt 30 Yr</td>\n",
       "      <td>3.908324</td>\n",
       "      <td>1.178592</td>\n",
       "      <td>1.16260</td>\n",
       "      <td>6.74700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>USGG3M</td>\n",
       "      <td>US Generic Govt 3 Mth</td>\n",
       "      <td>1.575151</td>\n",
       "      <td>1.802895</td>\n",
       "      <td>-0.03810</td>\n",
       "      <td>6.41400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>VIX</td>\n",
       "      <td>Cboe Volatility Index</td>\n",
       "      <td>19.992169</td>\n",
       "      <td>8.642157</td>\n",
       "      <td>9.43000</td>\n",
       "      <td>75.91000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>XAUBGNL</td>\n",
       "      <td>XAUBGNL</td>\n",
       "      <td>987.463744</td>\n",
       "      <td>494.623740</td>\n",
       "      <td>256.68000</td>\n",
       "      <td>2006.91000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ticker                     Description         Mean      Std.Dev  \\\n",
       "0        BDIY                Baltic Dry Index  2259.860486  2017.811888   \n",
       "1         CRY              TR/CC CRB ER Index   245.247649    68.278081   \n",
       "2         Cl1         Generic 1st 'CL' Future    60.708101    25.900813   \n",
       "3         DXY               DOLLAR INDEX SPOT    90.934982    11.379095   \n",
       "4    ECSURPUS  Bloomberg ECO US Surprise Inde     0.036153     0.349453   \n",
       "5    EMUSTRUU                EM USD Aggregate   704.379495   309.951768   \n",
       "6       EONIA  EMMI EURO OverNight Index Aver     1.363676     1.721894   \n",
       "7         GBP              British Pound Spot     1.569618     0.212340   \n",
       "8        GT10                 US TREASURY N/B     3.266748     1.332464   \n",
       "9    GTDEM10Y        BUNDESREPUB. DEUTSCHLAND     2.448365     1.851558   \n",
       "10    GTDEM2Y         BUNDESSCHATZANWEISUNGEN     1.431110     1.876061   \n",
       "11   GTDEM30Y        BUNDESREPUB. DEUTSCHLAND     3.039282     1.779526   \n",
       "12   GTGBP20Y              UK TSY 1 1/4% 2041     3.445731     1.366188   \n",
       "13    GTGBP2Y              UK TSY 0 1/8% 2023     2.299739     2.128539   \n",
       "14   GTGBP30Y              UK TSY 0 5/8% 2050     3.450121     1.263211   \n",
       "15  GTITL10YR        BUONI POLIENNALI DEL TES     3.680791     1.465289   \n",
       "16   GTITL2YR        BUONI POLIENNALI DEL TES     2.104911     1.700726   \n",
       "17  GTITL30YR        BUONI POLIENNALI DEL TES     4.426725     1.274729   \n",
       "18  GTJPY10YR           JAPAN (10 YEAR ISSUE)     0.904126     0.643985   \n",
       "19   GTJPY2YR            JAPAN (2 YEAR ISSUE)     0.150180     0.297519   \n",
       "20  GTJPY30YR           JAPAN (30 YEAR ISSUE)     1.724494     0.720026   \n",
       "21        JPY               Japanese Yen Spot   106.605734    12.840754   \n",
       "22   LF94TRUU         Global Inflation-Linked   259.052663    75.934443   \n",
       "23   LF98TRUU         US Corporate High Yield  1231.258119   553.121000   \n",
       "24   LG30TRUU               Global High Yield   804.720625   370.251996   \n",
       "25     LMBITR            Municipal Bond Index   883.615439   241.507125   \n",
       "26   LP01TREU         Pan-European High Yield   232.109928   109.917622   \n",
       "27   LUACTRUU                       Corporate  2077.306949   690.731794   \n",
       "28   LUMSTRUU                        U.S. MBS  1637.293510   417.229338   \n",
       "29       MXBR                     MSCI BRAZIL  1903.216436   986.468254   \n",
       "30       MXCN                      MSCI CHINA    53.933159    24.738356   \n",
       "31       MXEU                     MSCI EUROPE   107.877138    20.795973   \n",
       "32       MXIN                      MSCI INDIA   693.156616   405.527014   \n",
       "33       MXJP                      MSCI JAPAN   784.846292   200.076443   \n",
       "34       MXRU                     MSCI RUSSIA   648.681377   299.096020   \n",
       "35       MXUS                        MSCI USA  1606.997102   698.481956   \n",
       "36    US0001M           ICE LIBOR USD 1 Month     1.836073     1.909032   \n",
       "37    USGG2YR            US Generic Govt 2 Yr     1.990358     1.710307   \n",
       "38   USGG30YR           US Generic Govt 30 Yr     3.908324     1.178592   \n",
       "39     USGG3M           US Generic Govt 3 Mth     1.575151     1.802895   \n",
       "40        VIX           Cboe Volatility Index    19.992169     8.642157   \n",
       "41    XAUBGNL                         XAUBGNL   987.463744   494.623740   \n",
       "\n",
       "          Min          Max  Missing values Missing (%)  \n",
       "0   291.00000  11793.00000               0       0.00%  \n",
       "1   106.29290    467.57000               0       0.00%  \n",
       "2    10.01000    140.97000               0       0.00%  \n",
       "3    71.32900    119.82000               0       0.00%  \n",
       "4    -0.97400      0.99100               0       0.00%  \n",
       "5   230.52670   1286.35300               0       0.00%  \n",
       "6    -0.49800      5.73000               0       0.00%  \n",
       "7     1.17230      2.08520               0       0.00%  \n",
       "8     0.50800      6.74800               0       0.00%  \n",
       "9    -0.79400      5.64400               0       0.00%  \n",
       "10   -0.96800      5.26400               0       0.00%  \n",
       "11   -0.47100      6.25400               0       0.00%  \n",
       "12    0.48920      5.24180               0       0.00%  \n",
       "13   -0.16330      6.61250               0       0.00%  \n",
       "14    0.54740      5.07480               0       0.00%  \n",
       "15    0.51200      7.20900               0       0.00%  \n",
       "16   -0.45800      7.01500               0       0.00%  \n",
       "17    1.38600      7.50000               0       0.00%  \n",
       "18   -0.29100      1.96800               0       0.00%  \n",
       "19   -0.35100      1.08000               0       0.00%  \n",
       "20    0.05600      3.12800               0       0.00%  \n",
       "21   75.94000    134.63000               0       0.00%  \n",
       "22  121.33100    398.70650               0       0.00%  \n",
       "23  491.08000   2378.53000               0       0.00%  \n",
       "24  294.36740   1525.79000               0       0.00%  \n",
       "25  472.72330   1350.50000               0       0.00%  \n",
       "26   80.79680    431.55280               0       0.00%  \n",
       "27  986.94000   3550.43000               0       0.00%  \n",
       "28  869.33000   2325.86000               0       0.00%  \n",
       "29  280.50000   4721.36000               0       0.00%  \n",
       "30   13.46000    129.20000               0       0.00%  \n",
       "31   56.30000    146.39000               0       0.00%  \n",
       "32  112.60000   1730.51000               0       0.00%  \n",
       "33  431.71000   1210.58000               0       0.00%  \n",
       "34  151.25000   1617.64000               0       0.00%  \n",
       "35  663.69000   4043.69000               0       0.00%  \n",
       "36    0.10575      6.77625               0       0.00%  \n",
       "37    0.10730      6.87200               0       0.00%  \n",
       "38    1.16260      6.74700               0       0.00%  \n",
       "39   -0.03810      6.41400               0       0.00%  \n",
       "40    9.43000     75.91000               0       0.00%  \n",
       "41  256.68000   2006.91000               0       0.00%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set visualization style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "# Load the data from the Excel file\n",
    "# First sheet contains market data with dates and anomaly labels, second sheet contains metadata\n",
    "data_df = pd.read_excel(file_path, sheet_name='Markets')\n",
    "metadata_df = pd.read_excel(file_path, sheet_name='Metadata')\n",
    "\n",
    "# Check the structure of the loaded data\n",
    "print(\"Data columns:\", data_df.columns.tolist())\n",
    "\n",
    "# Extract date and anomaly label columns\n",
    "date_col = 'Date' if 'Date' in data_df.columns else data_df.columns[0]\n",
    "y_col = 'Y' if 'Y' in data_df.columns else None\n",
    "\n",
    "# Convert dates to datetime format\n",
    "data_df[date_col] = pd.to_datetime(data_df[date_col], dayfirst=True)  # Date format is dd/mm/yy\n",
    "\n",
    "# Set date as index\n",
    "data_df = data_df.set_index(date_col)\n",
    "\n",
    "# Extract features (all columns except Y if it exists)\n",
    "if y_col:\n",
    "    X_df = data_df.drop(y_col, axis=1)\n",
    "    y = data_df[y_col].values\n",
    "else:\n",
    "    X_df = data_df\n",
    "    y = None\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"Data shape: {X_df.shape}\")\n",
    "print(f\"Total number of records: {len(X_df)}\")\n",
    "print(f\"Time period: from {X_df.index.min().strftime('%m/%d/%Y')} to {X_df.index.max().strftime('%m/%d/%Y')}\")\n",
    "print(f\"Frequency: {pd.infer_freq(X_df.index) or 'Weekly'}\")\n",
    "print(f\"Number of variables: {X_df.shape[1]}\")\n",
    "if y_col:\n",
    "    print(f\"Number of anomalies: {np.sum(y == 1)} ({np.mean(y == 1)*100:.2f}%)\")\n",
    "\n",
    "# Create a more comprehensive metadata table with additional statistics\n",
    "enhanced_metadata = []\n",
    "\n",
    "# Determine the correct column names for ticker and description\n",
    "ticker_col = 'ticker' if 'ticker' in metadata_df.columns else metadata_df.columns[0]\n",
    "desc_col = 'description' if 'description' in metadata_df.columns else metadata_df.columns[1] if len(metadata_df.columns) > 1 else ticker_col\n",
    "\n",
    "for ticker in X_df.columns:\n",
    "    # Get metadata for this ticker if available\n",
    "    meta_row = metadata_df[metadata_df[ticker_col] == ticker] if ticker in metadata_df[ticker_col].values else pd.DataFrame()\n",
    "\n",
    "    # Get description or use ticker if not found\n",
    "    description = meta_row[desc_col].values[0] if not meta_row.empty and desc_col in meta_row.columns else ticker\n",
    "\n",
    "    # Calculate statistics for this series\n",
    "    series = X_df[ticker]\n",
    "\n",
    "    enhanced_metadata.append({\n",
    "        'Ticker': ticker,\n",
    "        'Description': description,\n",
    "        'Mean': series.mean(),\n",
    "        'Std.Dev': series.std(),\n",
    "        'Min': series.min(),\n",
    "        'Max': series.max(),\n",
    "        'Missing values': series.isna().sum(),\n",
    "        'Missing (%)': f\"{series.isna().mean()*100:.2f}%\"\n",
    "    })\n",
    "\n",
    "# Create enhanced metadata dataframe\n",
    "enhanced_meta_df = pd.DataFrame(enhanced_metadata)\n",
    "\n",
    "# Display the enhanced metadata\n",
    "print(\"\\nMetadata and statistics:\")\n",
    "display(enhanced_meta_df)\n",
    "\n",
    "# Create a plot with anomalies as vertical bars and MXUS as a line\n",
    "if y_col and 'MXUS' in X_df.columns:\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "    # Plot MXUS line\n",
    "    ax.plot(X_df.index, X_df['MXUS'], color='darkred', linewidth=2.5, label='MSCI USA')\n",
    "\n",
    "    # Get the y-axis limits after plotting MXUS\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "\n",
    "    # For each anomaly point (Y=1), create a vertical span across the entire plot\n",
    "    for i, (date, is_anomaly) in enumerate(zip(X_df.index, y)):\n",
    "        if is_anomaly == 1:\n",
    "            ax.axvspan(date, date + pd.Timedelta(days=7), alpha=0.3, color='navy', label='Risk-on/Risk-off' if i == 0 else \"\")\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Timeline')\n",
    "    ax.set_ylabel('MSCI USA')\n",
    "    ax.set_title('US Equities and risk-on/risk-off periods')\n",
    "\n",
    "    # Add legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax.legend(by_label.values(), by_label.keys(), loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Either 'Y' column or 'MXUS' column is missing in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8f2ac2",
   "metadata": {},
   "source": [
    "# LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58a1025",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c47110f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes detected: 2\n",
      "Class 0: 699 samples (78.72%)\n",
      "Class 1: 189 samples (21.28%)\n",
      "Using class weights: {0: 0.6351931330472103, 1: 2.3492063492063493}\n",
      "Prepared sequences: X shape = (848, 40, 42), y shape = (848,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built with 2 output classes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">114,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,232</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │       \u001b[38;5;34m114,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │           \u001b[38;5;34m800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m100,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │           \u001b[38;5;34m400\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m3,232\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m66\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">219,426</span> (857.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m219,426\u001b[0m (857.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">218,762</span> (854.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m218,762\u001b[0m (854.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">664</span> (2.59 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m664\u001b[0m (2.59 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 217ms/step - accuracy: 0.4975 - loss: 9.9254 - val_accuracy: 0.7294 - val_loss: 8.6207 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.6088 - loss: 8.4159 - val_accuracy: 0.7706 - val_loss: 7.5927 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.6293 - loss: 7.3740 - val_accuracy: 0.7824 - val_loss: 6.6864 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.6693 - loss: 6.5084 - val_accuracy: 0.7882 - val_loss: 5.9440 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.6928 - loss: 5.7336 - val_accuracy: 0.7882 - val_loss: 5.3230 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.7691 - loss: 5.0925 - val_accuracy: 0.7824 - val_loss: 4.7832 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.7463 - loss: 4.6207 - val_accuracy: 0.8059 - val_loss: 4.3258 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.7976 - loss: 4.1275 - val_accuracy: 0.8118 - val_loss: 3.9232 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.8023 - loss: 3.7202 - val_accuracy: 0.8118 - val_loss: 3.5718 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.8217 - loss: 3.3710 - val_accuracy: 0.8118 - val_loss: 3.2621 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.8303 - loss: 3.0677 - val_accuracy: 0.8000 - val_loss: 3.0326 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.8238 - loss: 2.8045 - val_accuracy: 0.8000 - val_loss: 2.7737 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.8565 - loss: 2.5712 - val_accuracy: 0.8059 - val_loss: 2.5807 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.8679 - loss: 2.3705 - val_accuracy: 0.8059 - val_loss: 2.3929 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.8659 - loss: 2.1981 - val_accuracy: 0.8176 - val_loss: 2.2260 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.8731 - loss: 1.9776 - val_accuracy: 0.8235 - val_loss: 2.0692 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.8745 - loss: 1.8894 - val_accuracy: 0.8353 - val_loss: 1.9374 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.8339 - loss: 1.8344 - val_accuracy: 0.8412 - val_loss: 1.8878 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.8635 - loss: 1.7593 - val_accuracy: 0.8294 - val_loss: 1.8076 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.8934 - loss: 1.5881 - val_accuracy: 0.8412 - val_loss: 1.7237 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.8734 - loss: 1.5259 - val_accuracy: 0.8412 - val_loss: 1.6187 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.8812 - loss: 1.4287 - val_accuracy: 0.8529 - val_loss: 1.5403 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.9098 - loss: 1.3101 - val_accuracy: 0.8588 - val_loss: 1.4784 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.9330 - loss: 1.2309 - val_accuracy: 0.8353 - val_loss: 1.4085 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.9048 - loss: 1.1768 - val_accuracy: 0.8471 - val_loss: 1.3850 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.8969 - loss: 1.1477 - val_accuracy: 0.8353 - val_loss: 1.3549 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.9042 - loss: 1.0723 - val_accuracy: 0.8235 - val_loss: 1.3103 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.9009 - loss: 1.0418 - val_accuracy: 0.8176 - val_loss: 1.2657 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.8802 - loss: 1.0390 - val_accuracy: 0.8059 - val_loss: 1.2728 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.8937 - loss: 1.0155 - val_accuracy: 0.8588 - val_loss: 1.2461 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.8943 - loss: 0.9800 - val_accuracy: 0.8412 - val_loss: 1.1947 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.9134 - loss: 0.8811 - val_accuracy: 0.8471 - val_loss: 1.1864 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9343 - loss: 0.8328 - val_accuracy: 0.8353 - val_loss: 1.1267 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.9236 - loss: 0.8005 - val_accuracy: 0.8471 - val_loss: 1.1268 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.9320 - loss: 0.7750 - val_accuracy: 0.8824 - val_loss: 1.0687 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9259 - loss: 0.7469 - val_accuracy: 0.8471 - val_loss: 1.1059 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9277 - loss: 0.7390 - val_accuracy: 0.8353 - val_loss: 1.1025 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.9263 - loss: 0.7362 - val_accuracy: 0.8412 - val_loss: 1.0366 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.9291 - loss: 0.6930 - val_accuracy: 0.8647 - val_loss: 0.9811 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.9005 - loss: 0.7298 - val_accuracy: 0.8529 - val_loss: 1.0220 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9086 - loss: 0.7823 - val_accuracy: 0.8647 - val_loss: 1.0548 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.8958 - loss: 0.7882 - val_accuracy: 0.8059 - val_loss: 1.1044 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.9015 - loss: 0.7242 - val_accuracy: 0.8471 - val_loss: 1.0168 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9149 - loss: 0.7073\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9144 - loss: 0.7082 - val_accuracy: 0.8235 - val_loss: 1.0744 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.8982 - loss: 0.6852 - val_accuracy: 0.8529 - val_loss: 1.0152 - learning_rate: 5.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9376 - loss: 0.6226 - val_accuracy: 0.8176 - val_loss: 1.0189 - learning_rate: 5.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.9298 - loss: 0.6263 - val_accuracy: 0.8235 - val_loss: 1.0246 - learning_rate: 5.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.9467 - loss: 0.5665 - val_accuracy: 0.8353 - val_loss: 0.9712 - learning_rate: 5.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.9385 - loss: 0.5618 - val_accuracy: 0.8353 - val_loss: 1.0162 - learning_rate: 5.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.9539 - loss: 0.5467 - val_accuracy: 0.8353 - val_loss: 1.0005 - learning_rate: 5.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.9378 - loss: 0.5547 - val_accuracy: 0.8294 - val_loss: 0.9548 - learning_rate: 5.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9463 - loss: 0.5197 - val_accuracy: 0.8235 - val_loss: 1.0285 - learning_rate: 5.0000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.9488 - loss: 0.5082 - val_accuracy: 0.8412 - val_loss: 0.9768 - learning_rate: 5.0000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9624 - loss: 0.4870 - val_accuracy: 0.8588 - val_loss: 0.9016 - learning_rate: 5.0000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.9647 - loss: 0.4613 - val_accuracy: 0.8529 - val_loss: 0.8896 - learning_rate: 5.0000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.9531 - loss: 0.5076 - val_accuracy: 0.8529 - val_loss: 0.9460 - learning_rate: 5.0000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.9368 - loss: 0.4682 - val_accuracy: 0.8647 - val_loss: 0.8684 - learning_rate: 5.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9582 - loss: 0.4428 - val_accuracy: 0.8647 - val_loss: 0.8972 - learning_rate: 5.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.9449 - loss: 0.4697 - val_accuracy: 0.8765 - val_loss: 0.8910 - learning_rate: 5.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.9439 - loss: 0.4687 - val_accuracy: 0.8706 - val_loss: 0.9036 - learning_rate: 5.0000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.9570 - loss: 0.4509 - val_accuracy: 0.8706 - val_loss: 0.8627 - learning_rate: 5.0000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.9598 - loss: 0.4102 - val_accuracy: 0.8765 - val_loss: 0.9078 - learning_rate: 5.0000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.9527 - loss: 0.4231 - val_accuracy: 0.8647 - val_loss: 0.9356 - learning_rate: 5.0000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.9482 - loss: 0.4348 - val_accuracy: 0.8471 - val_loss: 0.8355 - learning_rate: 5.0000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.9569 - loss: 0.4183 - val_accuracy: 0.8471 - val_loss: 0.8666 - learning_rate: 5.0000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.9708 - loss: 0.3988 - val_accuracy: 0.8471 - val_loss: 0.8746 - learning_rate: 5.0000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.9411 - loss: 0.4381 - val_accuracy: 0.8824 - val_loss: 0.8955 - learning_rate: 5.0000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.9471 - loss: 0.4327 - val_accuracy: 0.8294 - val_loss: 0.8711 - learning_rate: 5.0000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9319 - loss: 0.4413\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.9327 - loss: 0.4422 - val_accuracy: 0.8471 - val_loss: 0.9759 - learning_rate: 5.0000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.9448 - loss: 0.4516 - val_accuracy: 0.8353 - val_loss: 0.9849 - learning_rate: 2.5000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.9629 - loss: 0.3964 - val_accuracy: 0.8353 - val_loss: 0.9446 - learning_rate: 2.5000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9598 - loss: 0.3929 - val_accuracy: 0.8294 - val_loss: 0.9440 - learning_rate: 2.5000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.9730 - loss: 0.3679 - val_accuracy: 0.8412 - val_loss: 0.9089 - learning_rate: 2.5000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9568 - loss: 0.4075\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.9575 - loss: 0.4059 - val_accuracy: 0.8353 - val_loss: 0.9661 - learning_rate: 2.5000e-04\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Best validation accuracy: 0.8824 at epoch 35\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 317ms/step\n",
      "{'accuracy': 0.8852459016393442, 'precision': 0.8841807223796895, 'recall': 0.8852459016393442, 'f1': 0.8846780463072504}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[135  10]\n",
      " [ 11  27]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "class LSTMTimeSeriesClassifier:\n",
    "    \"\"\"\n",
    "    An improved LSTM-based time series classifier with enhanced training and evaluation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sequence_length=10, n_features=1, scaler_type='standard'):\n",
    "        \"\"\"\n",
    "        Initialize the classifier.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        sequence_length : int\n",
    "            The number of time steps in each input sequence.\n",
    "        n_features : int\n",
    "            The number of features at each time step.\n",
    "        scaler_type : str\n",
    "            Type of scaler to use ('standard' or 'minmax')\n",
    "        \"\"\"\n",
    "        self.sequence_length = sequence_length\n",
    "        self.n_features = n_features\n",
    "        self.model = None\n",
    "        \n",
    "        # Choose the appropriate scaler\n",
    "        if scaler_type.lower() == 'standard':\n",
    "            self.scaler = StandardScaler()\n",
    "        elif scaler_type.lower() == 'minmax':\n",
    "            self.scaler = MinMaxScaler()\n",
    "        else:\n",
    "            raise ValueError(\"scaler_type must be 'standard' or 'minmax'\")\n",
    "            \n",
    "        self.history = None\n",
    "        self.class_weights = None\n",
    "        \n",
    "    def build_model(self, n_classes, lstm_units_list=[100, 50], dropout_rate=0.3, \n",
    "                   learning_rate=0.001, bidirectional=True, l1_reg=0.0, l2_reg=0.001,\n",
    "                   kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal'):\n",
    "        \"\"\"\n",
    "        Build an improved LSTM model architecture with proper weights initialization.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_classes : int\n",
    "            The number of output classes.\n",
    "        lstm_units_list : list of int\n",
    "            Number of units for each LSTM layer.\n",
    "        dropout_rate : float\n",
    "            Dropout rate to prevent overfitting.\n",
    "        learning_rate : float\n",
    "            Learning rate for the Adam optimizer.\n",
    "        bidirectional : bool\n",
    "            Whether to use bidirectional LSTM layers.\n",
    "        l1_reg : float\n",
    "            L1 regularization factor.\n",
    "        l2_reg : float\n",
    "            L2 regularization factor.\n",
    "        kernel_initializer : str\n",
    "            Initializer for the kernel weights matrix (default: 'glorot_uniform').\n",
    "            Options: 'glorot_uniform', 'he_uniform', 'he_normal', etc.\n",
    "        recurrent_initializer : str\n",
    "            Initializer for the recurrent weights matrix (default: 'orthogonal').\n",
    "            Options: 'orthogonal', 'glorot_uniform', 'he_normal', etc.\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Regularization settings\n",
    "        reg = l1_l2(l1=l1_reg, l2=l2_reg)\n",
    "        \n",
    "        for i, units in enumerate(lstm_units_list):\n",
    "            return_sequences = i < len(lstm_units_list)-1  # True except for last layer\n",
    "            \n",
    "            # First layer needs input shape\n",
    "            if i == 0:\n",
    "                if bidirectional:\n",
    "                    model.add(Bidirectional(\n",
    "                        LSTM(units, activation='tanh', return_sequences=return_sequences,\n",
    "                            kernel_regularizer=reg, recurrent_regularizer=reg,\n",
    "                            kernel_initializer=kernel_initializer,\n",
    "                            recurrent_initializer=recurrent_initializer,\n",
    "                            bias_initializer='zeros'),\n",
    "                        input_shape=(self.sequence_length, self.n_features)\n",
    "                    ))\n",
    "                else:\n",
    "                    model.add(LSTM(\n",
    "                        units, activation='tanh', return_sequences=return_sequences,\n",
    "                        kernel_regularizer=reg, recurrent_regularizer=reg,\n",
    "                        kernel_initializer=kernel_initializer,\n",
    "                        recurrent_initializer=recurrent_initializer,\n",
    "                        bias_initializer='zeros',\n",
    "                        input_shape=(self.sequence_length, self.n_features)\n",
    "                    ))\n",
    "            else:\n",
    "                if bidirectional:\n",
    "                    model.add(Bidirectional(\n",
    "                        LSTM(units, activation='tanh', return_sequences=return_sequences,\n",
    "                            kernel_regularizer=reg, recurrent_regularizer=reg,\n",
    "                            kernel_initializer=kernel_initializer,\n",
    "                            recurrent_initializer=recurrent_initializer,\n",
    "                            bias_initializer='zeros')\n",
    "                    ))\n",
    "                else:\n",
    "                    model.add(LSTM(\n",
    "                        units, activation='tanh', return_sequences=return_sequences,\n",
    "                        kernel_regularizer=reg, recurrent_regularizer=reg,\n",
    "                        kernel_initializer=kernel_initializer,\n",
    "                        recurrent_initializer=recurrent_initializer,\n",
    "                        bias_initializer='zeros'\n",
    "                    ))\n",
    "            \n",
    "            # Add batch normalization and dropout after each LSTM layer\n",
    "            model.add(BatchNormalization(\n",
    "                beta_initializer='zeros',\n",
    "                gamma_initializer='ones',\n",
    "                moving_mean_initializer='zeros',\n",
    "                moving_variance_initializer='ones'\n",
    "            ))\n",
    "            model.add(Dropout(dropout_rate))\n",
    "        \n",
    "        # Add a dense hidden layer with batch normalization\n",
    "        model.add(Dense(32, activation='relu', \n",
    "                      kernel_regularizer=reg,\n",
    "                      kernel_initializer='he_uniform',  # He initialization is better for ReLU\n",
    "                      bias_initializer='zeros'))\n",
    "        model.add(BatchNormalization(\n",
    "            beta_initializer='zeros',\n",
    "            gamma_initializer='ones',\n",
    "            moving_mean_initializer='zeros',\n",
    "            moving_variance_initializer='ones'\n",
    "        ))\n",
    "        model.add(Dropout(dropout_rate/2))  # Reduced dropout for final layers\n",
    "        \n",
    "        # Output layer\n",
    "        model.add(Dense(n_classes, activation='softmax',\n",
    "                      kernel_initializer='glorot_uniform',  # Glorot/Xavier is good for softmax\n",
    "                      bias_initializer='zeros'))\n",
    "        \n",
    "        # Use Adam optimizer with customizable learning rate\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def prepare_sequences(self, data, labels=None, stride=1):\n",
    "        \"\"\"\n",
    "        Prepare time series data into overlapping sequences.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : array-like\n",
    "            Time series data of shape (n_samples, n_features).\n",
    "        labels : array-like, optional\n",
    "            Class labels for each time step.\n",
    "        stride : int\n",
    "            Step size between consecutive sequences (default: 1).\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        X : numpy.ndarray\n",
    "            Sequence data of shape (n_sequences, sequence_length, n_features).\n",
    "        y : numpy.ndarray or None\n",
    "            Labels for each sequence if labels are provided.\n",
    "        \"\"\"\n",
    "        # Ensure data is a numpy array\n",
    "        data = np.array(data)\n",
    "        \n",
    "        # Check if the data has the right shape\n",
    "        if len(data.shape) == 1:\n",
    "            # Convert 1D array to 2D with single feature\n",
    "            data = data.reshape(-1, 1)\n",
    "        \n",
    "        n_samples, n_features = data.shape\n",
    "        self.n_features = n_features\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        # Make sure we have enough data points to create at least one sequence\n",
    "        if n_samples <= self.sequence_length:\n",
    "            print(f\"Warning: Not enough samples ({n_samples}) for the given sequence length ({self.sequence_length}). Returning empty arrays.\")\n",
    "            return np.array(X), np.array(y)\n",
    "        \n",
    "        # Use stride to control overlap between sequences\n",
    "        for i in range(0, n_samples - self.sequence_length, stride):\n",
    "            X.append(data[i:i + self.sequence_length])\n",
    "            if labels is not None:\n",
    "                # Use the label at the end of the sequence\n",
    "                y.append(labels[i + self.sequence_length - 1])\n",
    "        \n",
    "        X = np.array(X)\n",
    "        \n",
    "        if labels is not None:\n",
    "            y = np.array(y)\n",
    "            return X, y\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def compute_class_weights(self, y):\n",
    "        \"\"\"\n",
    "        Compute class weights for imbalanced datasets.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        y : array-like\n",
    "            Class labels.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        class_weights : dict\n",
    "            Dictionary mapping class indices to weights.\n",
    "        \"\"\"\n",
    "        # Count number of samples in each class\n",
    "        unique_classes = np.unique(y)\n",
    "        class_counts = np.bincount(y)\n",
    "        \n",
    "        # Compute weights inversely proportional to class frequencies\n",
    "        total_samples = len(y)\n",
    "        n_classes = len(unique_classes)\n",
    "        \n",
    "        # Class weight calculation\n",
    "        class_weights = {}\n",
    "        for cls in unique_classes:\n",
    "            # Calculate weight as inverse of frequency, normalized\n",
    "            class_weights[cls] = total_samples / (n_classes * class_counts[cls])\n",
    "            \n",
    "        return class_weights\n",
    "    \n",
    "    def fit(self, X, y, epochs=1000, batch_size=32, validation_split=0.2, \n",
    "            verbose=1, use_class_weights=True, stride=1, learning_rate=0.001,\n",
    "            bidirectional=True, l1_reg=0.0, l2_reg=0.001,\n",
    "            kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal'):\n",
    "        \"\"\"\n",
    "        Train the LSTM model with improved training parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like\n",
    "            Time series data of shape (n_samples, n_features).\n",
    "        y : array-like\n",
    "            Class labels for each time step.\n",
    "        epochs : int\n",
    "            Number of training epochs.\n",
    "        batch_size : int\n",
    "            Batch size for training.\n",
    "        validation_split : float\n",
    "            Fraction of training data to use for validation.\n",
    "        verbose : int\n",
    "            Verbosity mode (0, 1, or 2).\n",
    "        use_class_weights : bool\n",
    "            Whether to use class weights for imbalanced datasets.\n",
    "        stride : int\n",
    "            Stride for sequence preparation (controls data augmentation).\n",
    "        learning_rate : float\n",
    "            Initial learning rate for the optimizer.\n",
    "        bidirectional : bool\n",
    "            Whether to use bidirectional LSTM layers.\n",
    "        l1_reg : float\n",
    "            L1 regularization factor.\n",
    "        l2_reg : float\n",
    "            L2 regularization factor.\n",
    "        augment_data : bool\n",
    "            Whether to apply time series data augmentation.\n",
    "        kernel_initializer : str\n",
    "            Initializer for the kernel weights matrix.\n",
    "        recurrent_initializer : str\n",
    "            Initializer for the recurrent weights matrix.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        self : LSTMTimeSeriesClassifier\n",
    "            The fitted classifier.\n",
    "        \"\"\"\n",
    "        # Convert inputs to numpy arrays if they're not already\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        # If X is a DataFrame, convert to numpy array\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        \n",
    "        # Handle 1D arrays\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "        \n",
    "        # Scale the features\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # Get number of unique classes\n",
    "        unique_classes = np.unique(y)\n",
    "        n_classes = len(unique_classes)\n",
    "        print(f\"Number of classes detected: {n_classes}\")\n",
    "        \n",
    "        # Print class distribution\n",
    "        class_counts = np.bincount(y)\n",
    "        for cls in unique_classes:\n",
    "            print(f\"Class {cls}: {class_counts[cls]} samples ({class_counts[cls]/len(y):.2%})\")\n",
    "        \n",
    "        # Compute class weights if requested and if class imbalance exists\n",
    "        if use_class_weights:\n",
    "            self.class_weights = self.compute_class_weights(y)\n",
    "            print(\"Using class weights:\", self.class_weights)\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "        \n",
    "        # Prepare sequences\n",
    "        try:\n",
    "            X_seq, y_seq = self.prepare_sequences(X_scaled, y, stride=stride)\n",
    "            print(f\"Prepared sequences: X shape = {X_seq.shape}, y shape = {y_seq.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error preparing sequences: {e}\")\n",
    "            raise\n",
    "        \n",
    "        # Build the model if not already built\n",
    "        if self.model is None:\n",
    "            self.model = self.build_model(\n",
    "                n_classes=n_classes,\n",
    "                learning_rate=learning_rate,\n",
    "                bidirectional=bidirectional,\n",
    "                l1_reg=l1_reg,\n",
    "                l2_reg=l2_reg,\n",
    "                kernel_initializer=kernel_initializer,\n",
    "                recurrent_initializer=recurrent_initializer\n",
    "            )\n",
    "            print(f\"Model built with {n_classes} output classes\")\n",
    "            \n",
    "        # Print model summary\n",
    "        self.model.summary()\n",
    "        \n",
    "        # Add callbacks for better training\n",
    "        callbacks = [\n",
    "            # Early stopping to prevent overfitting\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=10,  # Increased patience\n",
    "                restore_best_weights=True,\n",
    "                verbose=1\n",
    "            ),\n",
    "            # Learning rate reduction on plateau\n",
    "            ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=5,\n",
    "                min_lr=1e-6,\n",
    "                verbose=1\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Train the model\n",
    "        try:\n",
    "            self.history = self.model.fit(\n",
    "                X_seq, y_seq,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_split=validation_split,\n",
    "                callbacks=callbacks,\n",
    "                verbose=verbose,\n",
    "                class_weight=self.class_weights\n",
    "            )\n",
    "            \n",
    "            # Display training results\n",
    "            best_val_acc = max(self.history.history['val_accuracy'])\n",
    "            best_epoch = np.argmax(self.history.history['val_accuracy']) + 1\n",
    "            print(f\"Best validation accuracy: {best_val_acc:.4f} at epoch {best_epoch}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during model training: {e}\")\n",
    "            print(f\"X_seq shape: {X_seq.shape}\")\n",
    "            print(f\"y_seq shape: {y_seq.shape}\")\n",
    "            raise\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, X, return_probabilities=False):\n",
    "        \"\"\"\n",
    "        Make predictions on new data.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like\n",
    "            Time series data of shape (n_samples, n_features).\n",
    "        return_probabilities : bool\n",
    "            Whether to return class probabilities instead of class predictions.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        y_pred : numpy.ndarray\n",
    "            Predicted class labels or probabilities.\n",
    "        \"\"\"\n",
    "        # Convert to numpy array if needed\n",
    "        X = np.array(X)\n",
    "        \n",
    "        # Handle 1D arrays\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "            \n",
    "        # Scale the features\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        # Prepare sequences\n",
    "        X_seq = self.prepare_sequences(X_scaled)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_proba = self.model.predict(X_seq)\n",
    "        \n",
    "        if return_probabilities:\n",
    "            return y_pred_proba\n",
    "        else:\n",
    "            y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "            return y_pred\n",
    "    \n",
    "    def evaluate(self, X, y, threshold=None, average='weighted'):\n",
    "        \"\"\"\n",
    "        Evaluate the model on test data.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like\n",
    "            Time series data of shape (n_samples, n_features).\n",
    "        y : array-like\n",
    "            Class labels for each time step.\n",
    "        threshold : float, optional\n",
    "            Decision threshold for binary classification.\n",
    "        average : str\n",
    "            The type of averaging to use for multi-class metrics ('micro', 'macro', 'weighted').\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        metrics : dict\n",
    "            Dictionary of evaluation metrics.\n",
    "        \"\"\"\n",
    "        # Convert to numpy arrays\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        # Handle 1D arrays\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "            \n",
    "        # Scale the features\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        # Prepare sequences\n",
    "        X_seq, y_seq = self.prepare_sequences(X_scaled, y)\n",
    "        \n",
    "        # Check if we're dealing with binary classification\n",
    "        is_binary = len(np.unique(y_seq)) == 2\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_proba = self.model.predict(X_seq)\n",
    "        \n",
    "        if is_binary and threshold is not None:\n",
    "            # Binary classification with custom threshold\n",
    "            y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "        else:\n",
    "            # Default: argmax for multi-class or standard binary\n",
    "            y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "            \n",
    "        # Evaluate the model\n",
    "        loss, accuracy = self.model.evaluate(X_seq, y_seq, verbose=0)\n",
    "        \n",
    "        # Compute metrics\n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_seq, y_pred),\n",
    "            'precision': precision_score(y_seq, y_pred, average=average, zero_division=0),\n",
    "            'recall': recall_score(y_seq, y_pred, average=average, zero_division=0),\n",
    "            'f1': f1_score(y_seq, y_pred, average=average, zero_division=0)\n",
    "        }\n",
    "        \n",
    "        # Print classification report\n",
    "        print(metrics)\n",
    "        \n",
    "        # Print confusion matrix\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        cm = confusion_matrix(y_seq, y_pred)\n",
    "        print(cm)\n",
    "        \n",
    "                \n",
    "        return metrics, y_pred      \n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_df, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Initialize and train the classifier\n",
    "sequence_length = 40\n",
    "classifier = LSTMTimeSeriesClassifier(sequence_length=sequence_length)\n",
    "\n",
    "classifier.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    use_class_weights=True,\n",
    "    bidirectional=True,\n",
    "    l2_reg=0.01\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "metrics, y_pred = classifier.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb795474",
   "metadata": {},
   "source": [
    "# Let's try the focal loss\n",
    "The focal loss is GANZO, very FIGO, in particular is adapt for our problem where we have unbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee378b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes detected: 2\n",
      "Class 0: 699 samples (78.72%)\n",
      "Class 1: 189 samples (21.28%)\n",
      "Prepared sequences: X shape = (848, 40, 42), y shape = (848,)\n",
      "Model built with 2 output classes and focal loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">114,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,232</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_6 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │       \u001b[38;5;34m114,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │           \u001b[38;5;34m800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_7 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m100,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │           \u001b[38;5;34m400\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m3,232\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m66\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">219,426</span> (857.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m219,426\u001b[0m (857.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">218,762</span> (854.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m218,762\u001b[0m (854.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">664</span> (2.59 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m664\u001b[0m (2.59 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 114ms/step - accuracy: 0.4985 - loss: 8.6032 - val_accuracy: 0.6235 - val_loss: 6.5488 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.5827 - loss: 6.0797 - val_accuracy: 0.6176 - val_loss: 4.6335 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.6374 - loss: 4.3016 - val_accuracy: 0.6765 - val_loss: 3.2975 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6823 - loss: 3.0631 - val_accuracy: 0.7176 - val_loss: 2.3701 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7277 - loss: 2.2061 - val_accuracy: 0.7529 - val_loss: 1.7308 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.7481 - loss: 1.6242 - val_accuracy: 0.7529 - val_loss: 1.2898 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.7439 - loss: 1.2111 - val_accuracy: 0.7706 - val_loss: 0.9815 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7580 - loss: 0.9260 - val_accuracy: 0.7824 - val_loss: 0.7641 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7379 - loss: 0.7290 - val_accuracy: 0.7882 - val_loss: 0.6090 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7856 - loss: 0.5812 - val_accuracy: 0.7706 - val_loss: 0.4957 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7821 - loss: 0.4749 - val_accuracy: 0.7824 - val_loss: 0.4095 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.7677 - loss: 0.3971 - val_accuracy: 0.7882 - val_loss: 0.3421 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7993 - loss: 0.3279 - val_accuracy: 0.7941 - val_loss: 0.2910 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7931 - loss: 0.2808 - val_accuracy: 0.7824 - val_loss: 0.2473 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8234 - loss: 0.2342 - val_accuracy: 0.7765 - val_loss: 0.2128 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8255 - loss: 0.2005 - val_accuracy: 0.7706 - val_loss: 0.1866 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8048 - loss: 0.1825 - val_accuracy: 0.7706 - val_loss: 0.1656 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7985 - loss: 0.1612 - val_accuracy: 0.8059 - val_loss: 0.1463 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8033 - loss: 0.1405 - val_accuracy: 0.8000 - val_loss: 0.1303 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8336 - loss: 0.1212 - val_accuracy: 0.8000 - val_loss: 0.1164 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8207 - loss: 0.1091 - val_accuracy: 0.8000 - val_loss: 0.1037 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8507 - loss: 0.0982 - val_accuracy: 0.8059 - val_loss: 0.0953 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8226 - loss: 0.0913 - val_accuracy: 0.7941 - val_loss: 0.0865 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8253 - loss: 0.0807 - val_accuracy: 0.7941 - val_loss: 0.0812 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8308 - loss: 0.0793 - val_accuracy: 0.7882 - val_loss: 0.0788 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8281 - loss: 0.0760 - val_accuracy: 0.8059 - val_loss: 0.0746 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7770 - loss: 0.0802 - val_accuracy: 0.7941 - val_loss: 0.0744 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7755 - loss: 0.0774 - val_accuracy: 0.8059 - val_loss: 0.0743 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8424 - loss: 0.0699 - val_accuracy: 0.8294 - val_loss: 0.0657 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8432 - loss: 0.0612 - val_accuracy: 0.8118 - val_loss: 0.0606 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7995 - loss: 0.0600 - val_accuracy: 0.8235 - val_loss: 0.0577 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8227 - loss: 0.0537 - val_accuracy: 0.8118 - val_loss: 0.0535 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8455 - loss: 0.0493 - val_accuracy: 0.7941 - val_loss: 0.0520 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8206 - loss: 0.0481 - val_accuracy: 0.7941 - val_loss: 0.0496 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8224 - loss: 0.0452 - val_accuracy: 0.8118 - val_loss: 0.0490 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8143 - loss: 0.0485 - val_accuracy: 0.8118 - val_loss: 0.0544 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8445 - loss: 0.0443 - val_accuracy: 0.8294 - val_loss: 0.0453 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8450 - loss: 0.0412 - val_accuracy: 0.8412 - val_loss: 0.0432 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8302 - loss: 0.0447 - val_accuracy: 0.8176 - val_loss: 0.0459 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8108 - loss: 0.0476 - val_accuracy: 0.8706 - val_loss: 0.0437 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8268 - loss: 0.0418 - val_accuracy: 0.8412 - val_loss: 0.0415 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8533 - loss: 0.0392 - val_accuracy: 0.8353 - val_loss: 0.0425 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8169 - loss: 0.0394 - val_accuracy: 0.8412 - val_loss: 0.0412 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8488 - loss: 0.0384 - val_accuracy: 0.8529 - val_loss: 0.0396 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8373 - loss: 0.0394 - val_accuracy: 0.8529 - val_loss: 0.0369 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8505 - loss: 0.0358 - val_accuracy: 0.8353 - val_loss: 0.0368 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8694 - loss: 0.0338 - val_accuracy: 0.8471 - val_loss: 0.0358 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8536 - loss: 0.0353 - val_accuracy: 0.8647 - val_loss: 0.0343 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8568 - loss: 0.0344 - val_accuracy: 0.8353 - val_loss: 0.0355 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8539 - loss: 0.0331 - val_accuracy: 0.8059 - val_loss: 0.0396 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8535 - loss: 0.0346 - val_accuracy: 0.8647 - val_loss: 0.0356 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8628 - loss: 0.0322 - val_accuracy: 0.8647 - val_loss: 0.0359 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8464 - loss: 0.0338\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8453 - loss: 0.0339 - val_accuracy: 0.8588 - val_loss: 0.0358 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8565 - loss: 0.0345 - val_accuracy: 0.8529 - val_loss: 0.0344 - learning_rate: 5.0000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8511 - loss: 0.0312 - val_accuracy: 0.8471 - val_loss: 0.0361 - learning_rate: 5.0000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8758 - loss: 0.0297 - val_accuracy: 0.8529 - val_loss: 0.0336 - learning_rate: 5.0000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8670 - loss: 0.0300 - val_accuracy: 0.8529 - val_loss: 0.0316 - learning_rate: 5.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8830 - loss: 0.0272 - val_accuracy: 0.8412 - val_loss: 0.0351 - learning_rate: 5.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8799 - loss: 0.0285 - val_accuracy: 0.8588 - val_loss: 0.0324 - learning_rate: 5.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8737 - loss: 0.0295 - val_accuracy: 0.8294 - val_loss: 0.0323 - learning_rate: 5.0000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8754 - loss: 0.0280 - val_accuracy: 0.8412 - val_loss: 0.0351 - learning_rate: 5.0000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8627 - loss: 0.0307\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8621 - loss: 0.0309 - val_accuracy: 0.8647 - val_loss: 0.0334 - learning_rate: 5.0000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8727 - loss: 0.0286 - val_accuracy: 0.8471 - val_loss: 0.0328 - learning_rate: 2.5000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8867 - loss: 0.0271 - val_accuracy: 0.8353 - val_loss: 0.0339 - learning_rate: 2.5000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8834 - loss: 0.0257 - val_accuracy: 0.8588 - val_loss: 0.0296 - learning_rate: 2.5000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8868 - loss: 0.0250 - val_accuracy: 0.8706 - val_loss: 0.0300 - learning_rate: 2.5000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8915 - loss: 0.0246 - val_accuracy: 0.8765 - val_loss: 0.0306 - learning_rate: 2.5000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8799 - loss: 0.0251 - val_accuracy: 0.8765 - val_loss: 0.0298 - learning_rate: 2.5000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8774 - loss: 0.0249 - val_accuracy: 0.8824 - val_loss: 0.0294 - learning_rate: 2.5000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8937 - loss: 0.0226 - val_accuracy: 0.8706 - val_loss: 0.0287 - learning_rate: 2.5000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8857 - loss: 0.0240 - val_accuracy: 0.8882 - val_loss: 0.0292 - learning_rate: 2.5000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8920 - loss: 0.0234 - val_accuracy: 0.8824 - val_loss: 0.0283 - learning_rate: 2.5000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9094 - loss: 0.0223 - val_accuracy: 0.8647 - val_loss: 0.0300 - learning_rate: 2.5000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9300 - loss: 0.0203 - val_accuracy: 0.8706 - val_loss: 0.0293 - learning_rate: 2.5000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9124 - loss: 0.0222 - val_accuracy: 0.8824 - val_loss: 0.0279 - learning_rate: 2.5000e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8988 - loss: 0.0226 - val_accuracy: 0.8706 - val_loss: 0.0293 - learning_rate: 2.5000e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8790 - loss: 0.0253 - val_accuracy: 0.8824 - val_loss: 0.0283 - learning_rate: 2.5000e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8771 - loss: 0.0240 - val_accuracy: 0.8824 - val_loss: 0.0288 - learning_rate: 2.5000e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8968 - loss: 0.0245 - val_accuracy: 0.8412 - val_loss: 0.0415 - learning_rate: 2.5000e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8861 - loss: 0.0258\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8850 - loss: 0.0258 - val_accuracy: 0.8647 - val_loss: 0.0297 - learning_rate: 2.5000e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9157 - loss: 0.0221 - val_accuracy: 0.8529 - val_loss: 0.0318 - learning_rate: 1.2500e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8957 - loss: 0.0214 - val_accuracy: 0.8588 - val_loss: 0.0305 - learning_rate: 1.2500e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9033 - loss: 0.0212 - val_accuracy: 0.8706 - val_loss: 0.0293 - learning_rate: 1.2500e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9006 - loss: 0.0222 - val_accuracy: 0.8647 - val_loss: 0.0297 - learning_rate: 1.2500e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9211 - loss: 0.0203\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9210 - loss: 0.0203 - val_accuracy: 0.8765 - val_loss: 0.0283 - learning_rate: 1.2500e-04\n",
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 75.\n",
      "Best validation accuracy: 0.8882 at epoch 71\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 279ms/step\n",
      "{'accuracy': 0.8907103825136612, 'precision': 0.8925370186952509, 'recall': 0.8907103825136612, 'f1': 0.8789956784170864}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[143   2]\n",
      " [ 18  20]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    \"\"\"\n",
    "    Implementation of Focal Loss for multi-class classification.\n",
    "    \n",
    "    Focal Loss is designed to address class imbalance by down-weighting easy examples\n",
    "    and focusing more on hard examples.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gamma : float\n",
    "        Focusing parameter. Higher values mean more focus on hard examples.\n",
    "        Recommended values are between 0.5 and 5.\n",
    "    alpha : float or list/tensor\n",
    "        Class weight factor. Can be a single float or a tensor/list of weights per class.\n",
    "        If a single float, 'alpha' is the weight for class 1 and (1-alpha) for class 0.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    focal_loss_function : function\n",
    "        The focal loss function to use in model compilation.\n",
    "    \"\"\"\n",
    "    def focal_loss_function(y_true, y_pred):\n",
    "        # Clip the prediction to avoid log(0) errors\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        \n",
    "        # Convert labels to one-hot encoding if they aren't already\n",
    "        if K.ndim(y_true) == 1 or K.shape(y_true)[-1] == 1:\n",
    "            num_classes = K.shape(y_pred)[-1]\n",
    "            y_true = K.one_hot(K.cast(y_true, 'int32'), num_classes)\n",
    "        \n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "        \n",
    "        # Calculate focal loss\n",
    "        # (1 - y_pred) is the probability error term\n",
    "        # Higher gamma means more focus on hard examples\n",
    "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "        \n",
    "        # Sum over classes and average over samples\n",
    "        return K.mean(K.sum(loss, axis=-1))\n",
    "    \n",
    "    return focal_loss_function\n",
    "\n",
    "class LSTMTimeSeriesClassifier:\n",
    "    \"\"\"\n",
    "    An improved LSTM-based time series classifier with enhanced training and evaluation.\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "    def evaluate(self, X, y, threshold=None, average='weighted'):\n",
    "        \"\"\"\n",
    "        Evaluate the model on test data.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like\n",
    "            Time series data of shape (n_samples, n_features).\n",
    "        y : array-like\n",
    "            Class labels for each time step.\n",
    "        threshold : float, optional\n",
    "            Decision threshold for binary classification.\n",
    "        average : str\n",
    "            The type of averaging to use for multi-class metrics ('micro', 'macro', 'weighted').\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        metrics : dict\n",
    "            Dictionary of evaluation metrics.\n",
    "        \"\"\"\n",
    "        # Convert to numpy arrays\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        # Handle 1D arrays\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "            \n",
    "        # Scale the features\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        # Prepare sequences\n",
    "        X_seq, y_seq = self.prepare_sequences(X_scaled, y)\n",
    "        \n",
    "        # Check if we're dealing with binary classification\n",
    "        is_binary = len(np.unique(y_seq)) == 2\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_proba = self.model.predict(X_seq)\n",
    "        \n",
    "        if is_binary and threshold is not None:\n",
    "            # Binary classification with custom threshold\n",
    "            y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "        else:\n",
    "            # Default: argmax for multi-class or standard binary\n",
    "            y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "            \n",
    "        # Evaluate the model\n",
    "        loss, accuracy = self.model.evaluate(X_seq, y_seq, verbose=0)\n",
    "        \n",
    "        # Compute metrics\n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_seq, y_pred),\n",
    "            'precision': precision_score(y_seq, y_pred, average=average, zero_division=0),\n",
    "            'recall': recall_score(y_seq, y_pred, average=average, zero_division=0),\n",
    "            'f1': f1_score(y_seq, y_pred, average=average, zero_division=0)\n",
    "        }\n",
    "        \n",
    "        # Print classification report\n",
    "        print(metrics)\n",
    "        \n",
    "        # Print confusion matrix\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        cm = confusion_matrix(y_seq, y_pred)\n",
    "        print(cm)\n",
    "        \n",
    "                \n",
    "        return metrics, y_pred      \n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, sequence_length=10, n_features=1, scaler_type='standard'):\n",
    "        \"\"\"\n",
    "        Initialize the classifier.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        sequence_length : int\n",
    "            The number of time steps in each input sequence.\n",
    "        n_features : int\n",
    "            The number of features at each time step.\n",
    "        scaler_type : str\n",
    "            Type of scaler to use ('standard' or 'minmax')\n",
    "        \"\"\"\n",
    "        self.sequence_length = sequence_length\n",
    "        self.n_features = n_features\n",
    "        self.model = None\n",
    "        \n",
    "        # Choose the appropriate scaler\n",
    "        if scaler_type.lower() == 'standard':\n",
    "            self.scaler = StandardScaler()\n",
    "        elif scaler_type.lower() == 'minmax':\n",
    "            self.scaler = MinMaxScaler()\n",
    "        else:\n",
    "            raise ValueError(\"scaler_type must be 'standard' or 'minmax'\")\n",
    "            \n",
    "        self.history = None\n",
    "        self.class_weights = None\n",
    "        \n",
    "    def build_model(self, n_classes, lstm_units_list=[100, 50], dropout_rate=0.3, \n",
    "                   learning_rate=0.001, bidirectional=True, l1_reg=0.0, l2_reg=0.001,\n",
    "                   kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal',\n",
    "                   focal_loss_gamma=2.0, focal_loss_alpha=0.25):\n",
    "        \"\"\"\n",
    "        Build an improved LSTM model architecture with Focal Loss.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_classes : int\n",
    "            The number of output classes.\n",
    "        lstm_units_list : list of int\n",
    "            Number of units for each LSTM layer.\n",
    "        dropout_rate : float\n",
    "            Dropout rate to prevent overfitting.\n",
    "        learning_rate : float\n",
    "            Learning rate for the Adam optimizer.\n",
    "        bidirectional : bool\n",
    "            Whether to use bidirectional LSTM layers.\n",
    "        l1_reg : float\n",
    "            L1 regularization factor.\n",
    "        l2_reg : float\n",
    "            L2 regularization factor.\n",
    "        kernel_initializer : str\n",
    "            Initializer for the kernel weights matrix.\n",
    "        recurrent_initializer : str\n",
    "            Initializer for the recurrent weights matrix.\n",
    "        focal_loss_gamma : float\n",
    "            Focusing parameter for focal loss.\n",
    "        focal_loss_alpha : float or list\n",
    "            Class weight factor for focal loss.\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Regularization settings\n",
    "        reg = l1_l2(l1=l1_reg, l2=l2_reg)\n",
    "        \n",
    "        for i, units in enumerate(lstm_units_list):\n",
    "            return_sequences = i < len(lstm_units_list)-1  # True except for last layer\n",
    "            \n",
    "            # First layer needs input shape\n",
    "            if i == 0:\n",
    "                if bidirectional:\n",
    "                    model.add(Bidirectional(\n",
    "                        LSTM(units, activation='tanh', return_sequences=return_sequences,\n",
    "                            kernel_regularizer=reg, recurrent_regularizer=reg,\n",
    "                            kernel_initializer=kernel_initializer,\n",
    "                            recurrent_initializer=recurrent_initializer,\n",
    "                            bias_initializer='zeros'),\n",
    "                        input_shape=(self.sequence_length, self.n_features)\n",
    "                    ))\n",
    "                else:\n",
    "                    model.add(LSTM(\n",
    "                        units, activation='tanh', return_sequences=return_sequences,\n",
    "                        kernel_regularizer=reg, recurrent_regularizer=reg,\n",
    "                        kernel_initializer=kernel_initializer,\n",
    "                        recurrent_initializer=recurrent_initializer,\n",
    "                        bias_initializer='zeros',\n",
    "                        input_shape=(self.sequence_length, self.n_features)\n",
    "                    ))\n",
    "            else:\n",
    "                if bidirectional:\n",
    "                    model.add(Bidirectional(\n",
    "                        LSTM(units, activation='tanh', return_sequences=return_sequences,\n",
    "                            kernel_regularizer=reg, recurrent_regularizer=reg,\n",
    "                            kernel_initializer=kernel_initializer,\n",
    "                            recurrent_initializer=recurrent_initializer,\n",
    "                            bias_initializer='zeros')\n",
    "                    ))\n",
    "                else:\n",
    "                    model.add(LSTM(\n",
    "                        units, activation='tanh', return_sequences=return_sequences,\n",
    "                        kernel_regularizer=reg, recurrent_regularizer=reg,\n",
    "                        kernel_initializer=kernel_initializer,\n",
    "                        recurrent_initializer=recurrent_initializer,\n",
    "                        bias_initializer='zeros'\n",
    "                    ))\n",
    "            \n",
    "            # Add batch normalization and dropout after each LSTM layer\n",
    "            model.add(BatchNormalization(\n",
    "                beta_initializer='zeros',\n",
    "                gamma_initializer='ones',\n",
    "                moving_mean_initializer='zeros',\n",
    "                moving_variance_initializer='ones'\n",
    "            ))\n",
    "            model.add(Dropout(dropout_rate))\n",
    "        \n",
    "        # Add a dense hidden layer with batch normalization\n",
    "        model.add(Dense(32, activation='relu', \n",
    "                      kernel_regularizer=reg,\n",
    "                      kernel_initializer='he_uniform',  # He initialization is better for ReLU\n",
    "                      bias_initializer='zeros'))\n",
    "        model.add(BatchNormalization(\n",
    "            beta_initializer='zeros',\n",
    "            gamma_initializer='ones',\n",
    "            moving_mean_initializer='zeros',\n",
    "            moving_variance_initializer='ones'\n",
    "        ))\n",
    "        model.add(Dropout(dropout_rate/2))  # Reduced dropout for final layers\n",
    "        \n",
    "        # Output layer\n",
    "        model.add(Dense(n_classes, activation='softmax',\n",
    "                      kernel_initializer='glorot_uniform',  # Glorot/Xavier is good for softmax\n",
    "                      bias_initializer='zeros'))\n",
    "        \n",
    "        # Use Adam optimizer with customizable learning rate\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "        \n",
    "        # Define and use focal loss instead of sparse categorical crossentropy\n",
    "        loss_function = focal_loss(gamma=focal_loss_gamma, alpha=focal_loss_alpha)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss_function,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def prepare_sequences(self, data, labels=None, stride=1):\n",
    "        \"\"\"\n",
    "        Prepare time series data into overlapping sequences.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : array-like\n",
    "            Time series data of shape (n_samples, n_features).\n",
    "        labels : array-like, optional\n",
    "            Class labels for each time step.\n",
    "        stride : int\n",
    "            Step size between consecutive sequences (default: 1).\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        X : numpy.ndarray\n",
    "            Sequence data of shape (n_sequences, sequence_length, n_features).\n",
    "        y : numpy.ndarray or None\n",
    "            Labels for each sequence if labels are provided.\n",
    "        \"\"\"\n",
    "        # Ensure data is a numpy array\n",
    "        data = np.array(data)\n",
    "        \n",
    "        # Check if the data has the right shape\n",
    "        if len(data.shape) == 1:\n",
    "            # Convert 1D array to 2D with single feature\n",
    "            data = data.reshape(-1, 1)\n",
    "        \n",
    "        n_samples, n_features = data.shape\n",
    "        self.n_features = n_features\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        # Make sure we have enough data points to create at least one sequence\n",
    "        if n_samples <= self.sequence_length:\n",
    "            print(f\"Warning: Not enough samples ({n_samples}) for the given sequence length ({self.sequence_length}). Returning empty arrays.\")\n",
    "            return np.array(X), np.array(y)\n",
    "        \n",
    "        # Use stride to control overlap between sequences\n",
    "        for i in range(0, n_samples - self.sequence_length, stride):\n",
    "            X.append(data[i:i + self.sequence_length])\n",
    "            if labels is not None:\n",
    "                # Use the label at the end of the sequence\n",
    "                y.append(labels[i + self.sequence_length - 1])\n",
    "        \n",
    "        X = np.array(X)\n",
    "        \n",
    "        if labels is not None:\n",
    "            y = np.array(y)\n",
    "            return X, y\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def compute_class_weights(self, y):\n",
    "        \"\"\"\n",
    "        Compute class weights for imbalanced datasets.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        y : array-like\n",
    "            Class labels.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        class_weights : dict\n",
    "            Dictionary mapping class indices to weights.\n",
    "        \"\"\"\n",
    "        # Count number of samples in each class\n",
    "        unique_classes = np.unique(y)\n",
    "        class_counts = np.bincount(y)\n",
    "        \n",
    "        # Compute weights inversely proportional to class frequencies\n",
    "        total_samples = len(y)\n",
    "        n_classes = len(unique_classes)\n",
    "        \n",
    "        # Class weight calculation\n",
    "        class_weights = {}\n",
    "        for cls in unique_classes:\n",
    "            # Calculate weight as inverse of frequency, normalized\n",
    "            class_weights[cls] = total_samples / (n_classes * class_counts[cls])\n",
    "            \n",
    "        return class_weights\n",
    "    \n",
    "    def fit(self, X, y, epochs=1000, batch_size=32, validation_split=0.2, \n",
    "            verbose=1, use_class_weights=True, stride=1, learning_rate=0.001,\n",
    "            bidirectional=True, l1_reg=0.0, l2_reg=0.001,\n",
    "            kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal',\n",
    "            focal_loss_gamma=2.0, focal_loss_alpha=0.25):\n",
    "        \"\"\"\n",
    "        Train the LSTM model with Focal Loss.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like\n",
    "            Time series data of shape (n_samples, n_features).\n",
    "        y : array-like\n",
    "            Class labels for each time step.\n",
    "        epochs : int\n",
    "            Number of training epochs.\n",
    "        batch_size : int\n",
    "            Batch size for training.\n",
    "        validation_split : float\n",
    "            Fraction of training data to use for validation.\n",
    "        verbose : int\n",
    "            Verbosity mode (0, 1, or 2).\n",
    "        use_class_weights : bool\n",
    "            Whether to use class weights for imbalanced datasets.\n",
    "        stride : int\n",
    "            Stride for sequence preparation (controls data augmentation).\n",
    "        learning_rate : float\n",
    "            Initial learning rate for the optimizer.\n",
    "        bidirectional : bool\n",
    "            Whether to use bidirectional LSTM layers.\n",
    "        l1_reg : float\n",
    "            L1 regularization factor.\n",
    "        l2_reg : float\n",
    "            L2 regularization factor.\n",
    "        kernel_initializer : str\n",
    "            Initializer for the kernel weights matrix.\n",
    "        recurrent_initializer : str\n",
    "            Initializer for the recurrent weights matrix.\n",
    "        focal_loss_gamma : float\n",
    "            Focusing parameter for focal loss.\n",
    "        focal_loss_alpha : float or list\n",
    "            Class weight factor for focal loss.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        self : LSTMTimeSeriesClassifier\n",
    "            The fitted classifier.\n",
    "        \"\"\"\n",
    "        # Convert inputs to numpy arrays if they're not already\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        # If X is a DataFrame, convert to numpy array\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        \n",
    "        # Handle 1D arrays\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "        \n",
    "        # Scale the features\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # Get number of unique classes\n",
    "        unique_classes = np.unique(y)\n",
    "        n_classes = len(unique_classes)\n",
    "        print(f\"Number of classes detected: {n_classes}\")\n",
    "        \n",
    "        # Print class distribution\n",
    "        class_counts = np.bincount(y)\n",
    "        for cls in unique_classes:\n",
    "            print(f\"Class {cls}: {class_counts[cls]} samples ({class_counts[cls]/len(y):.2%})\")\n",
    "        \n",
    "        # If focal_loss_alpha is not a list or array, create balanced alpha values\n",
    "        if isinstance(focal_loss_alpha, (float, int)) and n_classes > 2:\n",
    "            # For multi-class, set alpha based on class frequencies if not specified\n",
    "            focal_loss_alpha = {i: 1 - (count / len(y)) for i, count in enumerate(class_counts)}\n",
    "            print(f\"Using calculated alpha values for focal loss: {focal_loss_alpha}\")\n",
    "        \n",
    "        # Compute class weights if requested (note: with focal loss, this might be redundant)\n",
    "        if use_class_weights:\n",
    "            self.class_weights = self.compute_class_weights(y)\n",
    "            print(\"Using class weights:\", self.class_weights)\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "        \n",
    "        # Prepare sequences\n",
    "        try:\n",
    "            X_seq, y_seq = self.prepare_sequences(X_scaled, y, stride=stride)\n",
    "            print(f\"Prepared sequences: X shape = {X_seq.shape}, y shape = {y_seq.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error preparing sequences: {e}\")\n",
    "            raise\n",
    "        \n",
    "        # Build the model if not already built\n",
    "        if self.model is None:\n",
    "            self.model = self.build_model(\n",
    "                n_classes=n_classes,\n",
    "                learning_rate=learning_rate,\n",
    "                bidirectional=bidirectional,\n",
    "                l1_reg=l1_reg,\n",
    "                l2_reg=l2_reg,\n",
    "                kernel_initializer=kernel_initializer,\n",
    "                recurrent_initializer=recurrent_initializer,\n",
    "                focal_loss_gamma=focal_loss_gamma,\n",
    "                focal_loss_alpha=focal_loss_alpha\n",
    "            )\n",
    "            print(f\"Model built with {n_classes} output classes and focal loss\")\n",
    "            \n",
    "        # Print model summary\n",
    "        self.model.summary()\n",
    "        \n",
    "        # Add callbacks for better training\n",
    "        callbacks = [\n",
    "            # Early stopping to prevent overfitting\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=10,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1\n",
    "            ),\n",
    "            # Learning rate reduction on plateau\n",
    "            ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=5,\n",
    "                min_lr=1e-6,\n",
    "                verbose=1\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Train the model\n",
    "        try:\n",
    "            self.history = self.model.fit(\n",
    "                X_seq, y_seq,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_split=validation_split,\n",
    "                callbacks=callbacks,\n",
    "                verbose=verbose,\n",
    "                class_weight=self.class_weights if use_class_weights else None\n",
    "            )\n",
    "            \n",
    "            # Display training results\n",
    "            best_val_acc = max(self.history.history['val_accuracy'])\n",
    "            best_epoch = np.argmax(self.history.history['val_accuracy']) + 1\n",
    "            print(f\"Best validation accuracy: {best_val_acc:.4f} at epoch {best_epoch}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during model training: {e}\")\n",
    "            print(f\"X_seq shape: {X_seq.shape}\")\n",
    "            print(f\"y_seq shape: {y_seq.shape}\")\n",
    "            raise\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, X, return_probabilities=False):\n",
    "        \"\"\"\n",
    "        Make predictions on new data.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like\n",
    "            Time series data of shape (n_samples, n_features).\n",
    "        return_probabilities : bool\n",
    "            Whether to return class probabilities instead of class predictions.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        y_pred : numpy.ndarray\n",
    "            Predicted class labels or probabilities.\n",
    "        \"\"\"\n",
    "        # Convert to numpy array if needed\n",
    "        X = np.array(X)\n",
    "        \n",
    "        # Handle 1D arrays\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "            \n",
    "        # Scale the features\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        # Prepare sequences\n",
    "        X_seq = self.prepare_sequences(X_scaled)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_proba = self.model.predict(X_seq)\n",
    "        \n",
    "        if return_probabilities:\n",
    "            return y_pred_proba\n",
    "        else:\n",
    "            y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "            return y_pred\n",
    "    \n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_df, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Example usage code:\n",
    "classifier = LSTMTimeSeriesClassifier(sequence_length=40)\n",
    "classifier.fit(\n",
    "     X_train, y_train,\n",
    "     epochs=100,\n",
    "     batch_size=32,\n",
    "     validation_split=0.2,\n",
    "     use_class_weights=False,\n",
    "     bidirectional=True,\n",
    "     l2_reg=0.01,\n",
    "     focal_loss_gamma=2.0,\n",
    "     focal_loss_alpha=0.25\n",
    "    )\n",
    "\n",
    "# Evaluate the model\n",
    "metrics, y_pred = classifier.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
