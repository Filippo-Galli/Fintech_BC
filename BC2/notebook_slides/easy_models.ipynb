{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup colab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "path = '/content/drive/MyDrive/PoliMI/Dataset1_BankClients.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **IMPORTANT**\n",
    "> Nel caso si utilizzi google Colab c'Ã¨ da caricare i file di input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path su linux\n",
    "file_path = '../data/Dataset2_Needs.xls'\n",
    "\n",
    "# Path su windows - comando da inserire \n",
    "#path = ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load each sheet into separate DataFrames\n",
    "needs_df = pd.read_excel(file_path, sheet_name='Needs')\n",
    "products_df = pd.read_excel(file_path, sheet_name='Products')\n",
    "metadata_df = pd.read_excel(file_path, sheet_name='Metadata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEEDS VARIABLES SUMMARY:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_76428_row0_col0, #T_76428_row0_col1, #T_76428_row0_col2, #T_76428_row0_col3, #T_76428_row0_col4, #T_76428_row0_col5, #T_76428_row0_col6, #T_76428_row1_col0, #T_76428_row1_col1, #T_76428_row1_col2, #T_76428_row1_col3, #T_76428_row1_col4, #T_76428_row1_col5, #T_76428_row1_col6, #T_76428_row2_col0, #T_76428_row2_col1, #T_76428_row2_col2, #T_76428_row2_col3, #T_76428_row2_col4, #T_76428_row2_col5, #T_76428_row2_col6, #T_76428_row3_col0, #T_76428_row3_col1, #T_76428_row3_col2, #T_76428_row3_col3, #T_76428_row3_col4, #T_76428_row3_col5, #T_76428_row3_col6, #T_76428_row4_col0, #T_76428_row4_col1, #T_76428_row4_col2, #T_76428_row4_col3, #T_76428_row4_col4, #T_76428_row4_col5, #T_76428_row4_col6, #T_76428_row5_col0, #T_76428_row5_col1, #T_76428_row5_col2, #T_76428_row5_col3, #T_76428_row5_col4, #T_76428_row5_col5, #T_76428_row5_col6, #T_76428_row6_col0, #T_76428_row6_col1, #T_76428_row6_col2, #T_76428_row6_col3, #T_76428_row6_col4, #T_76428_row6_col5, #T_76428_row6_col6, #T_76428_row7_col0, #T_76428_row7_col1, #T_76428_row7_col2, #T_76428_row7_col3, #T_76428_row7_col4, #T_76428_row7_col5, #T_76428_row7_col6, #T_76428_row8_col0, #T_76428_row8_col1, #T_76428_row8_col2, #T_76428_row8_col3, #T_76428_row8_col4, #T_76428_row8_col5, #T_76428_row8_col6, #T_76428_row9_col0, #T_76428_row9_col1, #T_76428_row9_col2, #T_76428_row9_col3, #T_76428_row9_col4, #T_76428_row9_col5, #T_76428_row9_col6 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_76428\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_76428_level0_col0\" class=\"col_heading level0 col0\" >Variable</th>\n",
       "      <th id=\"T_76428_level0_col1\" class=\"col_heading level0 col1\" >Description</th>\n",
       "      <th id=\"T_76428_level0_col2\" class=\"col_heading level0 col2\" >Mean</th>\n",
       "      <th id=\"T_76428_level0_col3\" class=\"col_heading level0 col3\" >Std</th>\n",
       "      <th id=\"T_76428_level0_col4\" class=\"col_heading level0 col4\" >Missing</th>\n",
       "      <th id=\"T_76428_level0_col5\" class=\"col_heading level0 col5\" >Min</th>\n",
       "      <th id=\"T_76428_level0_col6\" class=\"col_heading level0 col6\" >Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_76428_row0_col0\" class=\"data row0 col0\" >ID</td>\n",
       "      <td id=\"T_76428_row0_col1\" class=\"data row0 col1\" >Numerical ID</td>\n",
       "      <td id=\"T_76428_row0_col2\" class=\"data row0 col2\" >2500.50</td>\n",
       "      <td id=\"T_76428_row0_col3\" class=\"data row0 col3\" >1443.52</td>\n",
       "      <td id=\"T_76428_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_76428_row0_col5\" class=\"data row0 col5\" >1.00</td>\n",
       "      <td id=\"T_76428_row0_col6\" class=\"data row0 col6\" >5000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_76428_row1_col0\" class=\"data row1 col0\" >Age</td>\n",
       "      <td id=\"T_76428_row1_col1\" class=\"data row1 col1\" >Age, in years</td>\n",
       "      <td id=\"T_76428_row1_col2\" class=\"data row1 col2\" >55.25</td>\n",
       "      <td id=\"T_76428_row1_col3\" class=\"data row1 col3\" >11.97</td>\n",
       "      <td id=\"T_76428_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "      <td id=\"T_76428_row1_col5\" class=\"data row1 col5\" >18.00</td>\n",
       "      <td id=\"T_76428_row1_col6\" class=\"data row1 col6\" >97.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_76428_row2_col0\" class=\"data row2 col0\" >Gender</td>\n",
       "      <td id=\"T_76428_row2_col1\" class=\"data row2 col1\" >Gender (Female = 1, Male = 0)</td>\n",
       "      <td id=\"T_76428_row2_col2\" class=\"data row2 col2\" >0.49</td>\n",
       "      <td id=\"T_76428_row2_col3\" class=\"data row2 col3\" >0.50</td>\n",
       "      <td id=\"T_76428_row2_col4\" class=\"data row2 col4\" >0</td>\n",
       "      <td id=\"T_76428_row2_col5\" class=\"data row2 col5\" >0.00</td>\n",
       "      <td id=\"T_76428_row2_col6\" class=\"data row2 col6\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_76428_row3_col0\" class=\"data row3 col0\" >FamilyMembers</td>\n",
       "      <td id=\"T_76428_row3_col1\" class=\"data row3 col1\" >Number of components</td>\n",
       "      <td id=\"T_76428_row3_col2\" class=\"data row3 col2\" >2.51</td>\n",
       "      <td id=\"T_76428_row3_col3\" class=\"data row3 col3\" >0.76</td>\n",
       "      <td id=\"T_76428_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "      <td id=\"T_76428_row3_col5\" class=\"data row3 col5\" >1.00</td>\n",
       "      <td id=\"T_76428_row3_col6\" class=\"data row3 col6\" >5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_76428_row4_col0\" class=\"data row4 col0\" >FinancialEducation</td>\n",
       "      <td id=\"T_76428_row4_col1\" class=\"data row4 col1\" >Normalized level of Financial Education (estimate)</td>\n",
       "      <td id=\"T_76428_row4_col2\" class=\"data row4 col2\" >0.42</td>\n",
       "      <td id=\"T_76428_row4_col3\" class=\"data row4 col3\" >0.15</td>\n",
       "      <td id=\"T_76428_row4_col4\" class=\"data row4 col4\" >0</td>\n",
       "      <td id=\"T_76428_row4_col5\" class=\"data row4 col5\" >0.04</td>\n",
       "      <td id=\"T_76428_row4_col6\" class=\"data row4 col6\" >0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_76428_row5_col0\" class=\"data row5 col0\" >RiskPropensity</td>\n",
       "      <td id=\"T_76428_row5_col1\" class=\"data row5 col1\" >Normalized Risk propensity from MIFID profile</td>\n",
       "      <td id=\"T_76428_row5_col2\" class=\"data row5 col2\" >0.36</td>\n",
       "      <td id=\"T_76428_row5_col3\" class=\"data row5 col3\" >0.15</td>\n",
       "      <td id=\"T_76428_row5_col4\" class=\"data row5 col4\" >0</td>\n",
       "      <td id=\"T_76428_row5_col5\" class=\"data row5 col5\" >0.02</td>\n",
       "      <td id=\"T_76428_row5_col6\" class=\"data row5 col6\" >0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_76428_row6_col0\" class=\"data row6 col0\" >Income </td>\n",
       "      <td id=\"T_76428_row6_col1\" class=\"data row6 col1\" >Income (thousands of euros); estimate</td>\n",
       "      <td id=\"T_76428_row6_col2\" class=\"data row6 col2\" >62.99</td>\n",
       "      <td id=\"T_76428_row6_col3\" class=\"data row6 col3\" >44.36</td>\n",
       "      <td id=\"T_76428_row6_col4\" class=\"data row6 col4\" >0</td>\n",
       "      <td id=\"T_76428_row6_col5\" class=\"data row6 col5\" >1.54</td>\n",
       "      <td id=\"T_76428_row6_col6\" class=\"data row6 col6\" >365.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_76428_row7_col0\" class=\"data row7 col0\" >Wealth</td>\n",
       "      <td id=\"T_76428_row7_col1\" class=\"data row7 col1\" >Wealth (thousands of euros); sum of investments and cash accounts</td>\n",
       "      <td id=\"T_76428_row7_col2\" class=\"data row7 col2\" >93.81</td>\n",
       "      <td id=\"T_76428_row7_col3\" class=\"data row7 col3\" >105.47</td>\n",
       "      <td id=\"T_76428_row7_col4\" class=\"data row7 col4\" >0</td>\n",
       "      <td id=\"T_76428_row7_col5\" class=\"data row7 col5\" >1.06</td>\n",
       "      <td id=\"T_76428_row7_col6\" class=\"data row7 col6\" >2233.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_76428_row8_col0\" class=\"data row8 col0\" >IncomeInvestment</td>\n",
       "      <td id=\"T_76428_row8_col1\" class=\"data row8 col1\" >Boolean variable for Income investment; 1 = High propensity</td>\n",
       "      <td id=\"T_76428_row8_col2\" class=\"data row8 col2\" >0.38</td>\n",
       "      <td id=\"T_76428_row8_col3\" class=\"data row8 col3\" >0.49</td>\n",
       "      <td id=\"T_76428_row8_col4\" class=\"data row8 col4\" >0</td>\n",
       "      <td id=\"T_76428_row8_col5\" class=\"data row8 col5\" >0.00</td>\n",
       "      <td id=\"T_76428_row8_col6\" class=\"data row8 col6\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_76428_row9_col0\" class=\"data row9 col0\" >AccumulationInvestment</td>\n",
       "      <td id=\"T_76428_row9_col1\" class=\"data row9 col1\" >Boolean variable for Accumulation/growth investment; 1 = High propensity</td>\n",
       "      <td id=\"T_76428_row9_col2\" class=\"data row9 col2\" >0.51</td>\n",
       "      <td id=\"T_76428_row9_col3\" class=\"data row9 col3\" >0.50</td>\n",
       "      <td id=\"T_76428_row9_col4\" class=\"data row9 col4\" >0</td>\n",
       "      <td id=\"T_76428_row9_col5\" class=\"data row9 col5\" >0.00</td>\n",
       "      <td id=\"T_76428_row9_col6\" class=\"data row9 col6\" >1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f91874b5d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PRODUCTS VARIABLES SUMMARY:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b8a51_row0_col0, #T_b8a51_row0_col1, #T_b8a51_row0_col2, #T_b8a51_row0_col3, #T_b8a51_row0_col4, #T_b8a51_row0_col5, #T_b8a51_row0_col6, #T_b8a51_row1_col0, #T_b8a51_row1_col1, #T_b8a51_row1_col2, #T_b8a51_row1_col3, #T_b8a51_row1_col4, #T_b8a51_row1_col5, #T_b8a51_row1_col6, #T_b8a51_row2_col0, #T_b8a51_row2_col1, #T_b8a51_row2_col2, #T_b8a51_row2_col3, #T_b8a51_row2_col4, #T_b8a51_row2_col5, #T_b8a51_row2_col6 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b8a51\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_b8a51_level0_col0\" class=\"col_heading level0 col0\" >Variable</th>\n",
       "      <th id=\"T_b8a51_level0_col1\" class=\"col_heading level0 col1\" >Description</th>\n",
       "      <th id=\"T_b8a51_level0_col2\" class=\"col_heading level0 col2\" >Mean</th>\n",
       "      <th id=\"T_b8a51_level0_col3\" class=\"col_heading level0 col3\" >Std</th>\n",
       "      <th id=\"T_b8a51_level0_col4\" class=\"col_heading level0 col4\" >Missing</th>\n",
       "      <th id=\"T_b8a51_level0_col5\" class=\"col_heading level0 col5\" >Min</th>\n",
       "      <th id=\"T_b8a51_level0_col6\" class=\"col_heading level0 col6\" >Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_b8a51_row0_col0\" class=\"data row0 col0\" >IDProduct</td>\n",
       "      <td id=\"T_b8a51_row0_col1\" class=\"data row0 col1\" >Product description</td>\n",
       "      <td id=\"T_b8a51_row0_col2\" class=\"data row0 col2\" >6.00</td>\n",
       "      <td id=\"T_b8a51_row0_col3\" class=\"data row0 col3\" >3.32</td>\n",
       "      <td id=\"T_b8a51_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_b8a51_row0_col5\" class=\"data row0 col5\" >1.00</td>\n",
       "      <td id=\"T_b8a51_row0_col6\" class=\"data row0 col6\" >11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b8a51_row1_col0\" class=\"data row1 col0\" >Type</td>\n",
       "      <td id=\"T_b8a51_row1_col1\" class=\"data row1 col1\" >1 = Accumulation product, 0 = Income product </td>\n",
       "      <td id=\"T_b8a51_row1_col2\" class=\"data row1 col2\" >0.64</td>\n",
       "      <td id=\"T_b8a51_row1_col3\" class=\"data row1 col3\" >0.50</td>\n",
       "      <td id=\"T_b8a51_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "      <td id=\"T_b8a51_row1_col5\" class=\"data row1 col5\" >0.00</td>\n",
       "      <td id=\"T_b8a51_row1_col6\" class=\"data row1 col6\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b8a51_row2_col0\" class=\"data row2 col0\" >Risk</td>\n",
       "      <td id=\"T_b8a51_row2_col1\" class=\"data row2 col1\" >Normalized Synthetic Risk Indicator</td>\n",
       "      <td id=\"T_b8a51_row2_col2\" class=\"data row2 col2\" >0.43</td>\n",
       "      <td id=\"T_b8a51_row2_col3\" class=\"data row2 col3\" >0.24</td>\n",
       "      <td id=\"T_b8a51_row2_col4\" class=\"data row2 col4\" >0</td>\n",
       "      <td id=\"T_b8a51_row2_col5\" class=\"data row2 col5\" >0.12</td>\n",
       "      <td id=\"T_b8a51_row2_col6\" class=\"data row2 col6\" >0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9187ab4190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_variable_summary(df, metadata_df):\n",
    "    # Create empty lists to store the chosen statistics\n",
    "    stats_dict = {\n",
    "        'Variable': [],\n",
    "        'Description': [],\n",
    "        'Mean': [],\n",
    "        'Std': [],\n",
    "        'Missing': [],\n",
    "        'Min': [],\n",
    "        'Max': []\n",
    "    }\n",
    "\n",
    "    # Create a metadata dictionary for easy lookup\n",
    "    meta_dict = dict(zip(metadata_df['Metadata'], metadata_df['Unnamed: 1']))\n",
    "\n",
    "    for col in df.columns:\n",
    "        stats_dict['Variable'].append(col)\n",
    "        stats_dict['Description'].append(meta_dict.get(col, 'N/A'))\n",
    "\n",
    "        # Calculate some statistics for each column\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            stats_dict['Mean'].append(f\"{df[col].mean():.2f}\")\n",
    "            stats_dict['Std'].append(f\"{df[col].std():.2f}\")\n",
    "            stats_dict['Min'].append(f\"{df[col].min():.2f}\")\n",
    "            stats_dict['Max'].append(f\"{df[col].max():.2f}\")\n",
    "        else:\n",
    "            stats_dict['Mean'].append('N/A')\n",
    "            stats_dict['Std'].append('N/A')\n",
    "            stats_dict['Min'].append('N/A')\n",
    "            stats_dict['Max'].append('N/A')\n",
    "\n",
    "        stats_dict['Missing'].append(df[col].isna().sum())\n",
    "\n",
    "    return pd.DataFrame(stats_dict)\n",
    "\n",
    "\n",
    "# Create summary tables\n",
    "print(\"NEEDS VARIABLES SUMMARY:\")\n",
    "needs_summary = create_variable_summary(needs_df, metadata_df)\n",
    "display(needs_summary.style\n",
    "        .set_properties(**{'text-align': 'left'})\n",
    "        .hide(axis='index'))\n",
    "\n",
    "print(\"\\nPRODUCTS VARIABLES SUMMARY:\")\n",
    "products_summary = create_variable_summary(products_df, metadata_df)\n",
    "display(products_summary.style\n",
    "        .set_properties(**{'text-align': 'left'})\n",
    "        .hide(axis='index'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Change Wealth in log scale\n",
    "def prepare_features(df):\n",
    "    X = df.copy()\n",
    "\n",
    "    # Log transformation for Wealth and Income\n",
    "    X['Wealth_log'] = np.log1p(X['Wealth'])\n",
    "    X['Income_log'] = np.log1p(X['Income '])\n",
    "\n",
    "    # Select features for modeling\n",
    "    features_base = ['Age', 'Gender', 'FamilyMembers', 'FinancialEducation',\n",
    "                    'RiskPropensity', 'Wealth_log', 'Income_log']\n",
    "\n",
    "    # Normalize all features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_base = pd.DataFrame(scaler.fit_transform(X[features_base]), columns=features_base)\n",
    "\n",
    "    return X_base\n",
    "\n",
    "# Drop ID column as it's not needed for analysis\n",
    "needs_df = needs_df.drop('ID', axis=1)\n",
    "\n",
    "# Prepare features\n",
    "X_base = prepare_features(needs_df)\n",
    "y_income = needs_df['IncomeInvestment']\n",
    "y_accum = needs_df['AccumulationInvestment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Step 1: Feature engineering and transformation function\n",
    "def prepare_features(df):\n",
    "    X = df.copy()\n",
    "\n",
    "    # Log transformation for Wealth and Income\n",
    "    X['Wealth_log'] = np.log1p(X['Wealth'])\n",
    "    X['Income_log'] = np.log1p(X['Income '])\n",
    "\n",
    "    # Create Income/Wealth ratio\n",
    "    X['Income_Wealth_Ratio'] = X['Income '].div(X['Wealth'].replace(0, np.nan)).fillna(X['Income '].max())\n",
    "    X['Income_Wealth_Ratio_log'] = np.log1p(X['Income_Wealth_Ratio'])\n",
    "\n",
    "    # Select features for modeling\n",
    "    features_base = ['Age', 'Gender', 'FamilyMembers', 'FinancialEducation',\n",
    "                    'RiskPropensity', 'Wealth_log', 'Income_log']\n",
    "\n",
    "    features_engineered = ['Age', 'Gender', 'FamilyMembers', 'FinancialEducation',\n",
    "                          'RiskPropensity', 'Income_Wealth_Ratio_log']\n",
    "\n",
    "    # Normalize all features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_base = pd.DataFrame(scaler.fit_transform(X[features_base]), columns=features_base)\n",
    "    X_engineered = pd.DataFrame(scaler.fit_transform(X[features_engineered]), columns=features_engineered)\n",
    "\n",
    "    return X_base, X_engineered\n",
    "\n",
    "# Step 2: Data split function\n",
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Step 3: Model training and evaluation function\n",
    "def train_evaluate_model(X_train, y_train, X_test, y_test, model, k_folds=5):\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    cv_metrics = {\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': []\n",
    "    }\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_val_pred = model.predict(X_val_fold)\n",
    "\n",
    "        cv_metrics['accuracy'].append(accuracy_score(y_val_fold, y_val_pred))\n",
    "        cv_metrics['precision'].append(precision_score(y_val_fold, y_val_pred))\n",
    "        cv_metrics['recall'].append(recall_score(y_val_fold, y_val_pred))\n",
    "        cv_metrics['f1'].append(f1_score(y_val_fold, y_val_pred))\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    return {\n",
    "        'cv_metrics': {\n",
    "            metric: {\n",
    "                'mean': np.mean(scores),\n",
    "                'std': np.std(scores)\n",
    "            } for metric, scores in cv_metrics.items()\n",
    "        },\n",
    "        'test_metrics': {\n",
    "            'accuracy': accuracy_score(y_test, y_test_pred),\n",
    "            'precision': precision_score(y_test, y_test_pred),\n",
    "            'recall': recall_score(y_test, y_test_pred),\n",
    "            'f1': f1_score(y_test, y_test_pred)\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Step 4: Display results function\n",
    "def display_results_table(results_dict, model_name, feature_type):\n",
    "    cv_data = {\n",
    "        #'Metric': ['Accuracy', 'Precision', 'Recall', 'F1'],\n",
    "        'Metric': ['Precision', 'F1'],\n",
    "        'CV Mean': [\n",
    "            #results_dict['cv_metrics']['accuracy']['mean'],\n",
    "            results_dict['cv_metrics']['precision']['mean'],\n",
    "            #results_dict['cv_metrics']['recall']['mean'],\n",
    "            results_dict['cv_metrics']['f1']['mean']\n",
    "        ],\n",
    "        'CV Std': [\n",
    "            #results_dict['cv_metrics']['accuracy']['std'],\n",
    "            results_dict['cv_metrics']['precision']['std'],\n",
    "            #results_dict['cv_metrics']['recall']['std'],\n",
    "            results_dict['cv_metrics']['f1']['std']\n",
    "        ],\n",
    "        'Test Set': [\n",
    "            #results_dict['test_metrics']['accuracy'],\n",
    "            results_dict['test_metrics']['precision'],\n",
    "            #results_dict['test_metrics']['recall'],\n",
    "            results_dict['test_metrics']['f1']\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(cv_data)\n",
    "    df = df.round(3)\n",
    "\n",
    "    print(f\"\\n{model_name} - {feature_type}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(tabulate(df, headers='keys', tablefmt='pretty'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target Variable: Income Investment\n",
      "================================================================================\n",
      "\n",
      "SVM - Base Features\n",
      "============================================================\n",
      "+---+-----------+---------+--------+----------+\n",
      "|   |  Metric   | CV Mean | CV Std | Test Set |\n",
      "+---+-----------+---------+--------+----------+\n",
      "| 0 | Precision |  0.816  | 0.011  |  0.796   |\n",
      "| 1 |    F1     |  0.635  | 0.027  |  0.582   |\n",
      "+---+-----------+---------+--------+----------+\n",
      "\n",
      "RandomForest - Base Features\n",
      "============================================================\n",
      "+---+-----------+---------+--------+----------+\n",
      "|   |  Metric   | CV Mean | CV Std | Test Set |\n",
      "+---+-----------+---------+--------+----------+\n",
      "| 0 | Precision |  0.852  | 0.015  |  0.815   |\n",
      "| 1 |    F1     |  0.72   | 0.018  |  0.641   |\n",
      "+---+-----------+---------+--------+----------+\n",
      "\n",
      "Target Variable: Accumulation Investment\n",
      "================================================================================\n",
      "\n",
      "SVM - Base Features\n",
      "============================================================\n",
      "+---+-----------+---------+--------+----------+\n",
      "|   |  Metric   | CV Mean | CV Std | Test Set |\n",
      "+---+-----------+---------+--------+----------+\n",
      "| 0 | Precision |  0.706  | 0.023  |  0.686   |\n",
      "| 1 |    F1     |  0.713  | 0.016  |  0.719   |\n",
      "+---+-----------+---------+--------+----------+\n",
      "\n",
      "RandomForest - Base Features\n",
      "============================================================\n",
      "+---+-----------+---------+--------+----------+\n",
      "|   |  Metric   | CV Mean | CV Std | Test Set |\n",
      "+---+-----------+---------+--------+----------+\n",
      "| 0 | Precision |  0.827  | 0.022  |  0.804   |\n",
      "| 1 |    F1     |  0.779  | 0.017  |  0.776   |\n",
      "+---+-----------+---------+--------+----------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'SVM': SVC(),\n",
    "    #'NaiveBayes': GaussianNB(), \n",
    "    #'KNN': KNeighborsClassifier(n_neighbors=20),\n",
    "    #'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
    "    #'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "# Actually run analysis and display results\n",
    "for target_name, y in [('Income Investment', y_income), ('Accumulation Investment', y_accum)]:\n",
    "    print(f\"\\nTarget Variable: {target_name}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    X_base_train, X_base_test, y_train, y_test = split_data(X_base, y)\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        results_base = train_evaluate_model(X_base_train, y_train, X_base_test, y_test, model)\n",
    "        display_results_table(results_base, model_name, \"Base Features\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
